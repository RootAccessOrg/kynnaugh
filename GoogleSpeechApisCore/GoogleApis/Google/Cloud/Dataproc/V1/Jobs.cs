// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dataproc/v1/jobs.proto
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Cloud.Dataproc.V1 {

  /// <summary>Holder for reflection information generated from google/cloud/dataproc/v1/jobs.proto</summary>
  public static partial class JobsReflection {

    #region Descriptor
    /// <summary>File descriptor for google/cloud/dataproc/v1/jobs.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static JobsReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "CiNnb29nbGUvY2xvdWQvZGF0YXByb2MvdjEvam9icy5wcm90bxIYZ29vZ2xl",
            "LmNsb3VkLmRhdGFwcm9jLnYxGhxnb29nbGUvYXBpL2Fubm90YXRpb25zLnBy",
            "b3RvGhtnb29nbGUvcHJvdG9idWYvZW1wdHkucHJvdG8aH2dvb2dsZS9wcm90",
            "b2J1Zi90aW1lc3RhbXAucHJvdG8iwQIKDUxvZ2dpbmdDb25maWcSVwoRZHJp",
            "dmVyX2xvZ19sZXZlbHMYAiADKAsyPC5nb29nbGUuY2xvdWQuZGF0YXByb2Mu",
            "djEuTG9nZ2luZ0NvbmZpZy5Ecml2ZXJMb2dMZXZlbHNFbnRyeRplChREcml2",
            "ZXJMb2dMZXZlbHNFbnRyeRILCgNrZXkYASABKAkSPAoFdmFsdWUYAiABKA4y",
            "LS5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEuTG9nZ2luZ0NvbmZpZy5MZXZl",
            "bDoCOAEicAoFTGV2ZWwSFQoRTEVWRUxfVU5TUEVDSUZJRUQQABIHCgNBTEwQ",
            "ARIJCgVUUkFDRRACEgkKBURFQlVHEAMSCAoESU5GTxAEEggKBFdBUk4QBRIJ",
            "CgVFUlJPUhAGEgkKBUZBVEFMEAcSBwoDT0ZGEAgi0wIKCUhhZG9vcEpvYhIb",
            "ChFtYWluX2phcl9maWxlX3VyaRgBIAEoCUgAEhQKCm1haW5fY2xhc3MYAiAB",
            "KAlIABIMCgRhcmdzGAMgAygJEhUKDWphcl9maWxlX3VyaXMYBCADKAkSEQoJ",
            "ZmlsZV91cmlzGAUgAygJEhQKDGFyY2hpdmVfdXJpcxgGIAMoCRJHCgpwcm9w",
            "ZXJ0aWVzGAcgAygLMjMuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkhhZG9v",
            "cEpvYi5Qcm9wZXJ0aWVzRW50cnkSPwoObG9nZ2luZ19jb25maWcYCCABKAsy",
            "Jy5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEuTG9nZ2luZ0NvbmZpZxoxCg9Q",
            "cm9wZXJ0aWVzRW50cnkSCwoDa2V5GAEgASgJEg0KBXZhbHVlGAIgASgJOgI4",
            "AUIICgZkcml2ZXIi0QIKCFNwYXJrSm9iEhsKEW1haW5famFyX2ZpbGVfdXJp",
            "GAEgASgJSAASFAoKbWFpbl9jbGFzcxgCIAEoCUgAEgwKBGFyZ3MYAyADKAkS",
            "FQoNamFyX2ZpbGVfdXJpcxgEIAMoCRIRCglmaWxlX3VyaXMYBSADKAkSFAoM",
            "YXJjaGl2ZV91cmlzGAYgAygJEkYKCnByb3BlcnRpZXMYByADKAsyMi5nb29n",
            "bGUuY2xvdWQuZGF0YXByb2MudjEuU3BhcmtKb2IuUHJvcGVydGllc0VudHJ5",
            "Ej8KDmxvZ2dpbmdfY29uZmlnGAggASgLMicuZ29vZ2xlLmNsb3VkLmRhdGFw",
            "cm9jLnYxLkxvZ2dpbmdDb25maWcaMQoPUHJvcGVydGllc0VudHJ5EgsKA2tl",
            "eRgBIAEoCRINCgV2YWx1ZRgCIAEoCToCOAFCCAoGZHJpdmVyItACCgpQeVNw",
            "YXJrSm9iEhwKFG1haW5fcHl0aG9uX2ZpbGVfdXJpGAEgASgJEgwKBGFyZ3MY",
            "AiADKAkSGAoQcHl0aG9uX2ZpbGVfdXJpcxgDIAMoCRIVCg1qYXJfZmlsZV91",
            "cmlzGAQgAygJEhEKCWZpbGVfdXJpcxgFIAMoCRIUCgxhcmNoaXZlX3VyaXMY",
            "BiADKAkSSAoKcHJvcGVydGllcxgHIAMoCzI0Lmdvb2dsZS5jbG91ZC5kYXRh",
            "cHJvYy52MS5QeVNwYXJrSm9iLlByb3BlcnRpZXNFbnRyeRI/Cg5sb2dnaW5n",
            "X2NvbmZpZxgIIAEoCzInLmdvb2dsZS5jbG91ZC5kYXRhcHJvYy52MS5Mb2dn",
            "aW5nQ29uZmlnGjEKD1Byb3BlcnRpZXNFbnRyeRILCgNrZXkYASABKAkSDQoF",
            "dmFsdWUYAiABKAk6AjgBIhwKCVF1ZXJ5TGlzdBIPCgdxdWVyaWVzGAEgAygJ",
            "IqEDCgdIaXZlSm9iEhgKDnF1ZXJ5X2ZpbGVfdXJpGAEgASgJSAASOQoKcXVl",
            "cnlfbGlzdBgCIAEoCzIjLmdvb2dsZS5jbG91ZC5kYXRhcHJvYy52MS5RdWVy",
            "eUxpc3RIABIbChNjb250aW51ZV9vbl9mYWlsdXJlGAMgASgIElAKEHNjcmlw",
            "dF92YXJpYWJsZXMYBCADKAsyNi5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEu",
            "SGl2ZUpvYi5TY3JpcHRWYXJpYWJsZXNFbnRyeRJFCgpwcm9wZXJ0aWVzGAUg",
            "AygLMjEuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkhpdmVKb2IuUHJvcGVy",
            "dGllc0VudHJ5EhUKDWphcl9maWxlX3VyaXMYBiADKAkaNgoUU2NyaXB0VmFy",
            "aWFibGVzRW50cnkSCwoDa2V5GAEgASgJEg0KBXZhbHVlGAIgASgJOgI4ARox",
            "Cg9Qcm9wZXJ0aWVzRW50cnkSCwoDa2V5GAEgASgJEg0KBXZhbHVlGAIgASgJ",
            "OgI4AUIJCgdxdWVyaWVzItEDCgtTcGFya1NxbEpvYhIYCg5xdWVyeV9maWxl",
            "X3VyaRgBIAEoCUgAEjkKCnF1ZXJ5X2xpc3QYAiABKAsyIy5nb29nbGUuY2xv",
            "dWQuZGF0YXByb2MudjEuUXVlcnlMaXN0SAASVAoQc2NyaXB0X3ZhcmlhYmxl",
            "cxgDIAMoCzI6Lmdvb2dsZS5jbG91ZC5kYXRhcHJvYy52MS5TcGFya1NxbEpv",
            "Yi5TY3JpcHRWYXJpYWJsZXNFbnRyeRJJCgpwcm9wZXJ0aWVzGAQgAygLMjUu",
            "Z29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLlNwYXJrU3FsSm9iLlByb3BlcnRp",
            "ZXNFbnRyeRIVCg1qYXJfZmlsZV91cmlzGDggAygJEj8KDmxvZ2dpbmdfY29u",
            "ZmlnGAYgASgLMicuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkxvZ2dpbmdD",
            "b25maWcaNgoUU2NyaXB0VmFyaWFibGVzRW50cnkSCwoDa2V5GAEgASgJEg0K",
            "BXZhbHVlGAIgASgJOgI4ARoxCg9Qcm9wZXJ0aWVzRW50cnkSCwoDa2V5GAEg",
            "ASgJEg0KBXZhbHVlGAIgASgJOgI4AUIJCgdxdWVyaWVzIt8DCgZQaWdKb2IS",
            "GAoOcXVlcnlfZmlsZV91cmkYASABKAlIABI5CgpxdWVyeV9saXN0GAIgASgL",
            "MiMuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLlF1ZXJ5TGlzdEgAEhsKE2Nv",
            "bnRpbnVlX29uX2ZhaWx1cmUYAyABKAgSTwoQc2NyaXB0X3ZhcmlhYmxlcxgE",
            "IAMoCzI1Lmdvb2dsZS5jbG91ZC5kYXRhcHJvYy52MS5QaWdKb2IuU2NyaXB0",
            "VmFyaWFibGVzRW50cnkSRAoKcHJvcGVydGllcxgFIAMoCzIwLmdvb2dsZS5j",
            "bG91ZC5kYXRhcHJvYy52MS5QaWdKb2IuUHJvcGVydGllc0VudHJ5EhUKDWph",
            "cl9maWxlX3VyaXMYBiADKAkSPwoObG9nZ2luZ19jb25maWcYByABKAsyJy5n",
            "b29nbGUuY2xvdWQuZGF0YXByb2MudjEuTG9nZ2luZ0NvbmZpZxo2ChRTY3Jp",
            "cHRWYXJpYWJsZXNFbnRyeRILCgNrZXkYASABKAkSDQoFdmFsdWUYAiABKAk6",
            "AjgBGjEKD1Byb3BlcnRpZXNFbnRyeRILCgNrZXkYASABKAkSDQoFdmFsdWUY",
            "AiABKAk6AjgBQgkKB3F1ZXJpZXMiOgoMSm9iUGxhY2VtZW50EhQKDGNsdXN0",
            "ZXJfbmFtZRgBIAEoCRIUCgxjbHVzdGVyX3V1aWQYAiABKAkiowIKCUpvYlN0",
            "YXR1cxI4CgVzdGF0ZRgBIAEoDjIpLmdvb2dsZS5jbG91ZC5kYXRhcHJvYy52",
            "MS5Kb2JTdGF0dXMuU3RhdGUSDwoHZGV0YWlscxgCIAEoCRI0ChBzdGF0ZV9z",
            "dGFydF90aW1lGAYgASgLMhouZ29vZ2xlLnByb3RvYnVmLlRpbWVzdGFtcCKU",
            "AQoFU3RhdGUSFQoRU1RBVEVfVU5TUEVDSUZJRUQQABILCgdQRU5ESU5HEAES",
            "DgoKU0VUVVBfRE9ORRAIEgsKB1JVTk5JTkcQAhISCg5DQU5DRUxfUEVORElO",
            "RxADEhIKDkNBTkNFTF9TVEFSVEVEEAcSDQoJQ0FOQ0VMTEVEEAQSCAoERE9O",
            "RRAFEgkKBUVSUk9SEAYiMgoMSm9iUmVmZXJlbmNlEhIKCnByb2plY3RfaWQY",
            "ASABKAkSDgoGam9iX2lkGAIgASgJIpwFCgNKb2ISOQoJcmVmZXJlbmNlGAEg",
            "ASgLMiYuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkpvYlJlZmVyZW5jZRI5",
            "CglwbGFjZW1lbnQYAiABKAsyJi5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEu",
            "Sm9iUGxhY2VtZW50EjkKCmhhZG9vcF9qb2IYAyABKAsyIy5nb29nbGUuY2xv",
            "dWQuZGF0YXByb2MudjEuSGFkb29wSm9iSAASNwoJc3Bhcmtfam9iGAQgASgL",
            "MiIuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLlNwYXJrSm9iSAASOwoLcHlz",
            "cGFya19qb2IYBSABKAsyJC5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEuUHlT",
            "cGFya0pvYkgAEjUKCGhpdmVfam9iGAYgASgLMiEuZ29vZ2xlLmNsb3VkLmRh",
            "dGFwcm9jLnYxLkhpdmVKb2JIABIzCgdwaWdfam9iGAcgASgLMiAuZ29vZ2xl",
            "LmNsb3VkLmRhdGFwcm9jLnYxLlBpZ0pvYkgAEj4KDXNwYXJrX3NxbF9qb2IY",
            "DCABKAsyJS5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEuU3BhcmtTcWxKb2JI",
            "ABIzCgZzdGF0dXMYCCABKAsyIy5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEu",
            "Sm9iU3RhdHVzEjsKDnN0YXR1c19oaXN0b3J5GA0gAygLMiMuZ29vZ2xlLmNs",
            "b3VkLmRhdGFwcm9jLnYxLkpvYlN0YXR1cxIiChpkcml2ZXJfb3V0cHV0X3Jl",
            "c291cmNlX3VyaRgRIAEoCRIgChhkcml2ZXJfY29udHJvbF9maWxlc191cmkY",
            "DyABKAlCCgoIdHlwZV9qb2IiYgoQU3VibWl0Sm9iUmVxdWVzdBISCgpwcm9q",
            "ZWN0X2lkGAEgASgJEg4KBnJlZ2lvbhgDIAEoCRIqCgNqb2IYAiABKAsyHS5n",
            "b29nbGUuY2xvdWQuZGF0YXByb2MudjEuSm9iIkMKDUdldEpvYlJlcXVlc3QS",
            "EgoKcHJvamVjdF9pZBgBIAEoCRIOCgZyZWdpb24YAyABKAkSDgoGam9iX2lk",
            "GAIgASgJIoACCg9MaXN0Sm9ic1JlcXVlc3QSEgoKcHJvamVjdF9pZBgBIAEo",
            "CRIOCgZyZWdpb24YBiABKAkSEQoJcGFnZV9zaXplGAIgASgFEhIKCnBhZ2Vf",
            "dG9rZW4YAyABKAkSFAoMY2x1c3Rlcl9uYW1lGAQgASgJElQKEWpvYl9zdGF0",
            "ZV9tYXRjaGVyGAUgASgOMjkuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkxp",
            "c3RKb2JzUmVxdWVzdC5Kb2JTdGF0ZU1hdGNoZXIiNgoPSm9iU3RhdGVNYXRj",
            "aGVyEgcKA0FMTBAAEgoKBkFDVElWRRABEg4KCk5PTl9BQ1RJVkUQAiJYChBM",
            "aXN0Sm9ic1Jlc3BvbnNlEisKBGpvYnMYASADKAsyHS5nb29nbGUuY2xvdWQu",
            "ZGF0YXByb2MudjEuSm9iEhcKD25leHRfcGFnZV90b2tlbhgCIAEoCSJGChBD",
            "YW5jZWxKb2JSZXF1ZXN0EhIKCnByb2plY3RfaWQYASABKAkSDgoGcmVnaW9u",
            "GAMgASgJEg4KBmpvYl9pZBgCIAEoCSJGChBEZWxldGVKb2JSZXF1ZXN0EhIK",
            "CnByb2plY3RfaWQYASABKAkSDgoGcmVnaW9uGAMgASgJEg4KBmpvYl9pZBgC",
            "IAEoCTKWBgoNSm9iQ29udHJvbGxlchKZAQoJU3VibWl0Sm9iEiouZ29vZ2xl",
            "LmNsb3VkLmRhdGFwcm9jLnYxLlN1Ym1pdEpvYlJlcXVlc3QaHS5nb29nbGUu",
            "Y2xvdWQuZGF0YXByb2MudjEuSm9iIkGC0+STAjsiNi92MS9wcm9qZWN0cy97",
            "cHJvamVjdF9pZH0vcmVnaW9ucy97cmVnaW9ufS9qb2JzOnN1Ym1pdDoBKhKS",
            "AQoGR2V0Sm9iEicuZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkdldEpvYlJl",
            "cXVlc3QaHS5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEuSm9iIkCC0+STAjoS",
            "OC92MS9wcm9qZWN0cy97cHJvamVjdF9pZH0vcmVnaW9ucy97cmVnaW9ufS9q",
            "b2JzL3tqb2JfaWR9EpoBCghMaXN0Sm9icxIpLmdvb2dsZS5jbG91ZC5kYXRh",
            "cHJvYy52MS5MaXN0Sm9ic1JlcXVlc3QaKi5nb29nbGUuY2xvdWQuZGF0YXBy",
            "b2MudjEuTGlzdEpvYnNSZXNwb25zZSI3gtPkkwIxEi8vdjEvcHJvamVjdHMv",
            "e3Byb2plY3RfaWR9L3JlZ2lvbnMve3JlZ2lvbn0vam9icxKiAQoJQ2FuY2Vs",
            "Sm9iEiouZ29vZ2xlLmNsb3VkLmRhdGFwcm9jLnYxLkNhbmNlbEpvYlJlcXVl",
            "c3QaHS5nb29nbGUuY2xvdWQuZGF0YXByb2MudjEuSm9iIkqC0+STAkQiPy92",
            "MS9wcm9qZWN0cy97cHJvamVjdF9pZH0vcmVnaW9ucy97cmVnaW9ufS9qb2Jz",
            "L3tqb2JfaWR9OmNhbmNlbDoBKhKRAQoJRGVsZXRlSm9iEiouZ29vZ2xlLmNs",
            "b3VkLmRhdGFwcm9jLnYxLkRlbGV0ZUpvYlJlcXVlc3QaFi5nb29nbGUucHJv",
            "dG9idWYuRW1wdHkiQILT5JMCOio4L3YxL3Byb2plY3RzL3twcm9qZWN0X2lk",
            "fS9yZWdpb25zL3tyZWdpb259L2pvYnMve2pvYl9pZH1CbQocY29tLmdvb2ds",
            "ZS5jbG91ZC5kYXRhcHJvYy52MUIJSm9ic1Byb3RvUAFaQGdvb2dsZS5nb2xh",
            "bmcub3JnL2dlbnByb3RvL2dvb2dsZWFwaXMvY2xvdWQvZGF0YXByb2MvdjE7",
            "ZGF0YXByb2NiBnByb3RvMw=="));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.AnnotationsReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.EmptyReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.TimestampReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.LoggingConfig), global::Google.Cloud.Dataproc.V1.LoggingConfig.Parser, new[]{ "DriverLogLevels" }, null, new[]{ typeof(global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level) }, new pbr::GeneratedClrTypeInfo[] { null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.HadoopJob), global::Google.Cloud.Dataproc.V1.HadoopJob.Parser, new[]{ "MainJarFileUri", "MainClass", "Args", "JarFileUris", "FileUris", "ArchiveUris", "Properties", "LoggingConfig" }, new[]{ "Driver" }, null, new pbr::GeneratedClrTypeInfo[] { null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.SparkJob), global::Google.Cloud.Dataproc.V1.SparkJob.Parser, new[]{ "MainJarFileUri", "MainClass", "Args", "JarFileUris", "FileUris", "ArchiveUris", "Properties", "LoggingConfig" }, new[]{ "Driver" }, null, new pbr::GeneratedClrTypeInfo[] { null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.PySparkJob), global::Google.Cloud.Dataproc.V1.PySparkJob.Parser, new[]{ "MainPythonFileUri", "Args", "PythonFileUris", "JarFileUris", "FileUris", "ArchiveUris", "Properties", "LoggingConfig" }, null, null, new pbr::GeneratedClrTypeInfo[] { null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.QueryList), global::Google.Cloud.Dataproc.V1.QueryList.Parser, new[]{ "Queries" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.HiveJob), global::Google.Cloud.Dataproc.V1.HiveJob.Parser, new[]{ "QueryFileUri", "QueryList", "ContinueOnFailure", "ScriptVariables", "Properties", "JarFileUris" }, new[]{ "Queries" }, null, new pbr::GeneratedClrTypeInfo[] { null, null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.SparkSqlJob), global::Google.Cloud.Dataproc.V1.SparkSqlJob.Parser, new[]{ "QueryFileUri", "QueryList", "ScriptVariables", "Properties", "JarFileUris", "LoggingConfig" }, new[]{ "Queries" }, null, new pbr::GeneratedClrTypeInfo[] { null, null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.PigJob), global::Google.Cloud.Dataproc.V1.PigJob.Parser, new[]{ "QueryFileUri", "QueryList", "ContinueOnFailure", "ScriptVariables", "Properties", "JarFileUris", "LoggingConfig" }, new[]{ "Queries" }, null, new pbr::GeneratedClrTypeInfo[] { null, null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.JobPlacement), global::Google.Cloud.Dataproc.V1.JobPlacement.Parser, new[]{ "ClusterName", "ClusterUuid" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.JobStatus), global::Google.Cloud.Dataproc.V1.JobStatus.Parser, new[]{ "State", "Details", "StateStartTime" }, null, new[]{ typeof(global::Google.Cloud.Dataproc.V1.JobStatus.Types.State) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.JobReference), global::Google.Cloud.Dataproc.V1.JobReference.Parser, new[]{ "ProjectId", "JobId" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.Job), global::Google.Cloud.Dataproc.V1.Job.Parser, new[]{ "Reference", "Placement", "HadoopJob", "SparkJob", "PysparkJob", "HiveJob", "PigJob", "SparkSqlJob", "Status", "StatusHistory", "DriverOutputResourceUri", "DriverControlFilesUri" }, new[]{ "TypeJob" }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.SubmitJobRequest), global::Google.Cloud.Dataproc.V1.SubmitJobRequest.Parser, new[]{ "ProjectId", "Region", "Job" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.GetJobRequest), global::Google.Cloud.Dataproc.V1.GetJobRequest.Parser, new[]{ "ProjectId", "Region", "JobId" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.ListJobsRequest), global::Google.Cloud.Dataproc.V1.ListJobsRequest.Parser, new[]{ "ProjectId", "Region", "PageSize", "PageToken", "ClusterName", "JobStateMatcher" }, null, new[]{ typeof(global::Google.Cloud.Dataproc.V1.ListJobsRequest.Types.JobStateMatcher) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.ListJobsResponse), global::Google.Cloud.Dataproc.V1.ListJobsResponse.Parser, new[]{ "Jobs", "NextPageToken" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.CancelJobRequest), global::Google.Cloud.Dataproc.V1.CancelJobRequest.Parser, new[]{ "ProjectId", "Region", "JobId" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dataproc.V1.DeleteJobRequest), global::Google.Cloud.Dataproc.V1.DeleteJobRequest.Parser, new[]{ "ProjectId", "Region", "JobId" }, null, null, null)
          }));
    }
    #endregion

  }
  #region Messages
  /// <summary>
  ///  The runtime logging config of the job.
  /// </summary>
  public sealed partial class LoggingConfig : pb::IMessage<LoggingConfig> {
    private static readonly pb::MessageParser<LoggingConfig> _parser = new pb::MessageParser<LoggingConfig>(() => new LoggingConfig());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<LoggingConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LoggingConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LoggingConfig(LoggingConfig other) : this() {
      driverLogLevels_ = other.driverLogLevels_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LoggingConfig Clone() {
      return new LoggingConfig(this);
    }

    /// <summary>Field number for the "driver_log_levels" field.</summary>
    public const int DriverLogLevelsFieldNumber = 2;
    private static readonly pbc::MapField<string, global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level>.Codec _map_driverLogLevels_codec
        = new pbc::MapField<string, global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForEnum(16, x => (int) x, x => (global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level) x), 18);
    private readonly pbc::MapField<string, global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level> driverLogLevels_ = new pbc::MapField<string, global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level>();
    /// <summary>
    ///  The per-package log levels for the driver. This may include
    ///  "root" package name to configure rootLogger.
    ///  Examples:
    ///    'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, global::Google.Cloud.Dataproc.V1.LoggingConfig.Types.Level> DriverLogLevels {
      get { return driverLogLevels_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as LoggingConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(LoggingConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!DriverLogLevels.Equals(other.DriverLogLevels)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= DriverLogLevels.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      driverLogLevels_.WriteTo(output, _map_driverLogLevels_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += driverLogLevels_.CalculateSize(_map_driverLogLevels_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(LoggingConfig other) {
      if (other == null) {
        return;
      }
      driverLogLevels_.Add(other.driverLogLevels_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 18: {
            driverLogLevels_.AddEntriesFrom(input, _map_driverLogLevels_codec);
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the LoggingConfig message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      ///  The Log4j level for job execution. When running an
      ///  [Apache Hive](http://hive.apache.org/) job, Cloud
      ///  Dataproc configures the Hive client to an equivalent verbosity level.
      /// </summary>
      public enum Level {
        /// <summary>
        ///  Level is unspecified. Use default level for log4j.
        /// </summary>
        [pbr::OriginalName("LEVEL_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        ///  Use ALL level for log4j.
        /// </summary>
        [pbr::OriginalName("ALL")] All = 1,
        /// <summary>
        ///  Use TRACE level for log4j.
        /// </summary>
        [pbr::OriginalName("TRACE")] Trace = 2,
        /// <summary>
        ///  Use DEBUG level for log4j.
        /// </summary>
        [pbr::OriginalName("DEBUG")] Debug = 3,
        /// <summary>
        ///  Use INFO level for log4j.
        /// </summary>
        [pbr::OriginalName("INFO")] Info = 4,
        /// <summary>
        ///  Use WARN level for log4j.
        /// </summary>
        [pbr::OriginalName("WARN")] Warn = 5,
        /// <summary>
        ///  Use ERROR level for log4j.
        /// </summary>
        [pbr::OriginalName("ERROR")] Error = 6,
        /// <summary>
        ///  Use FATAL level for log4j.
        /// </summary>
        [pbr::OriginalName("FATAL")] Fatal = 7,
        /// <summary>
        ///  Turn off log4j.
        /// </summary>
        [pbr::OriginalName("OFF")] Off = 8,
      }

    }
    #endregion

  }

  /// <summary>
  ///  A Cloud Dataproc job for running
  ///  [Apache Hadoop MapReduce](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
  ///  jobs on [Apache Hadoop YARN](https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
  /// </summary>
  public sealed partial class HadoopJob : pb::IMessage<HadoopJob> {
    private static readonly pb::MessageParser<HadoopJob> _parser = new pb::MessageParser<HadoopJob>(() => new HadoopJob());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<HadoopJob> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public HadoopJob() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public HadoopJob(HadoopJob other) : this() {
      args_ = other.args_.Clone();
      jarFileUris_ = other.jarFileUris_.Clone();
      fileUris_ = other.fileUris_.Clone();
      archiveUris_ = other.archiveUris_.Clone();
      properties_ = other.properties_.Clone();
      LoggingConfig = other.loggingConfig_ != null ? other.LoggingConfig.Clone() : null;
      switch (other.DriverCase) {
        case DriverOneofCase.MainJarFileUri:
          MainJarFileUri = other.MainJarFileUri;
          break;
        case DriverOneofCase.MainClass:
          MainClass = other.MainClass;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public HadoopJob Clone() {
      return new HadoopJob(this);
    }

    /// <summary>Field number for the "main_jar_file_uri" field.</summary>
    public const int MainJarFileUriFieldNumber = 1;
    /// <summary>
    ///  The HCFS URI of the jar file containing the main class.
    ///  Examples:
    ///      'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar'
    ///      'hdfs:/tmp/test-samples/custom-wordcount.jar'
    ///      'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string MainJarFileUri {
      get { return driverCase_ == DriverOneofCase.MainJarFileUri ? (string) driver_ : ""; }
      set {
        driver_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        driverCase_ = DriverOneofCase.MainJarFileUri;
      }
    }

    /// <summary>Field number for the "main_class" field.</summary>
    public const int MainClassFieldNumber = 2;
    /// <summary>
    ///  The name of the driver's main class. The jar file containing the class
    ///  must be in the default CLASSPATH or specified in `jar_file_uris`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string MainClass {
      get { return driverCase_ == DriverOneofCase.MainClass ? (string) driver_ : ""; }
      set {
        driver_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        driverCase_ = DriverOneofCase.MainClass;
      }
    }

    /// <summary>Field number for the "args" field.</summary>
    public const int ArgsFieldNumber = 3;
    private static readonly pb::FieldCodec<string> _repeated_args_codec
        = pb::FieldCodec.ForString(26);
    private readonly pbc::RepeatedField<string> args_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] The arguments to pass to the driver. Do not
    ///  include arguments, such as `-libjars` or `-Dfoo=bar`, that can be set as job
    ///  properties, since a collision may occur that causes an incorrect job
    ///  submission.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Args {
      get { return args_; }
    }

    /// <summary>Field number for the "jar_file_uris" field.</summary>
    public const int JarFileUrisFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_jarFileUris_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> jarFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] Jar file URIs to add to the CLASSPATHs of the
    ///  Hadoop driver and tasks.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> JarFileUris {
      get { return jarFileUris_; }
    }

    /// <summary>Field number for the "file_uris" field.</summary>
    public const int FileUrisFieldNumber = 5;
    private static readonly pb::FieldCodec<string> _repeated_fileUris_codec
        = pb::FieldCodec.ForString(42);
    private readonly pbc::RepeatedField<string> fileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS (Hadoop Compatible Filesystem) URIs of files to be copied
    ///  to the working directory of Hadoop drivers and distributed tasks. Useful
    ///  for naively parallel tasks.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> FileUris {
      get { return fileUris_; }
    }

    /// <summary>Field number for the "archive_uris" field.</summary>
    public const int ArchiveUrisFieldNumber = 6;
    private static readonly pb::FieldCodec<string> _repeated_archiveUris_codec
        = pb::FieldCodec.ForString(50);
    private readonly pbc::RepeatedField<string> archiveUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of archives to be extracted in the working directory of
    ///  Hadoop drivers and tasks. Supported file types:
    ///  .jar, .tar, .tar.gz, .tgz, or .zip.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> ArchiveUris {
      get { return archiveUris_; }
    }

    /// <summary>Field number for the "properties" field.</summary>
    public const int PropertiesFieldNumber = 7;
    private static readonly pbc::MapField<string, string>.Codec _map_properties_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 58);
    private readonly pbc::MapField<string, string> properties_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] A mapping of property names to values, used to configure Hadoop.
    ///  Properties that conflict with values set by the Cloud Dataproc API may be
    ///  overwritten. Can include properties set in /etc/hadoop/conf/*-site and
    ///  classes in user code.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> Properties {
      get { return properties_; }
    }

    /// <summary>Field number for the "logging_config" field.</summary>
    public const int LoggingConfigFieldNumber = 8;
    private global::Google.Cloud.Dataproc.V1.LoggingConfig loggingConfig_;
    /// <summary>
    ///  [Optional] The runtime log config for job execution.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.LoggingConfig LoggingConfig {
      get { return loggingConfig_; }
      set {
        loggingConfig_ = value;
      }
    }

    private object driver_;
    /// <summary>Enum of possible cases for the "driver" oneof.</summary>
    public enum DriverOneofCase {
      None = 0,
      MainJarFileUri = 1,
      MainClass = 2,
    }
    private DriverOneofCase driverCase_ = DriverOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public DriverOneofCase DriverCase {
      get { return driverCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearDriver() {
      driverCase_ = DriverOneofCase.None;
      driver_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as HadoopJob);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(HadoopJob other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (MainJarFileUri != other.MainJarFileUri) return false;
      if (MainClass != other.MainClass) return false;
      if(!args_.Equals(other.args_)) return false;
      if(!jarFileUris_.Equals(other.jarFileUris_)) return false;
      if(!fileUris_.Equals(other.fileUris_)) return false;
      if(!archiveUris_.Equals(other.archiveUris_)) return false;
      if (!Properties.Equals(other.Properties)) return false;
      if (!object.Equals(LoggingConfig, other.LoggingConfig)) return false;
      if (DriverCase != other.DriverCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (driverCase_ == DriverOneofCase.MainJarFileUri) hash ^= MainJarFileUri.GetHashCode();
      if (driverCase_ == DriverOneofCase.MainClass) hash ^= MainClass.GetHashCode();
      hash ^= args_.GetHashCode();
      hash ^= jarFileUris_.GetHashCode();
      hash ^= fileUris_.GetHashCode();
      hash ^= archiveUris_.GetHashCode();
      hash ^= Properties.GetHashCode();
      if (loggingConfig_ != null) hash ^= LoggingConfig.GetHashCode();
      hash ^= (int) driverCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (driverCase_ == DriverOneofCase.MainJarFileUri) {
        output.WriteRawTag(10);
        output.WriteString(MainJarFileUri);
      }
      if (driverCase_ == DriverOneofCase.MainClass) {
        output.WriteRawTag(18);
        output.WriteString(MainClass);
      }
      args_.WriteTo(output, _repeated_args_codec);
      jarFileUris_.WriteTo(output, _repeated_jarFileUris_codec);
      fileUris_.WriteTo(output, _repeated_fileUris_codec);
      archiveUris_.WriteTo(output, _repeated_archiveUris_codec);
      properties_.WriteTo(output, _map_properties_codec);
      if (loggingConfig_ != null) {
        output.WriteRawTag(66);
        output.WriteMessage(LoggingConfig);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (driverCase_ == DriverOneofCase.MainJarFileUri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(MainJarFileUri);
      }
      if (driverCase_ == DriverOneofCase.MainClass) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(MainClass);
      }
      size += args_.CalculateSize(_repeated_args_codec);
      size += jarFileUris_.CalculateSize(_repeated_jarFileUris_codec);
      size += fileUris_.CalculateSize(_repeated_fileUris_codec);
      size += archiveUris_.CalculateSize(_repeated_archiveUris_codec);
      size += properties_.CalculateSize(_map_properties_codec);
      if (loggingConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(LoggingConfig);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(HadoopJob other) {
      if (other == null) {
        return;
      }
      args_.Add(other.args_);
      jarFileUris_.Add(other.jarFileUris_);
      fileUris_.Add(other.fileUris_);
      archiveUris_.Add(other.archiveUris_);
      properties_.Add(other.properties_);
      if (other.loggingConfig_ != null) {
        if (loggingConfig_ == null) {
          loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
        }
        LoggingConfig.MergeFrom(other.LoggingConfig);
      }
      switch (other.DriverCase) {
        case DriverOneofCase.MainJarFileUri:
          MainJarFileUri = other.MainJarFileUri;
          break;
        case DriverOneofCase.MainClass:
          MainClass = other.MainClass;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            MainJarFileUri = input.ReadString();
            break;
          }
          case 18: {
            MainClass = input.ReadString();
            break;
          }
          case 26: {
            args_.AddEntriesFrom(input, _repeated_args_codec);
            break;
          }
          case 34: {
            jarFileUris_.AddEntriesFrom(input, _repeated_jarFileUris_codec);
            break;
          }
          case 42: {
            fileUris_.AddEntriesFrom(input, _repeated_fileUris_codec);
            break;
          }
          case 50: {
            archiveUris_.AddEntriesFrom(input, _repeated_archiveUris_codec);
            break;
          }
          case 58: {
            properties_.AddEntriesFrom(input, _map_properties_codec);
            break;
          }
          case 66: {
            if (loggingConfig_ == null) {
              loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
            }
            input.ReadMessage(loggingConfig_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A Cloud Dataproc job for running [Apache Spark](http://spark.apache.org/)
  ///  applications on YARN.
  /// </summary>
  public sealed partial class SparkJob : pb::IMessage<SparkJob> {
    private static readonly pb::MessageParser<SparkJob> _parser = new pb::MessageParser<SparkJob>(() => new SparkJob());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SparkJob> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SparkJob() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SparkJob(SparkJob other) : this() {
      args_ = other.args_.Clone();
      jarFileUris_ = other.jarFileUris_.Clone();
      fileUris_ = other.fileUris_.Clone();
      archiveUris_ = other.archiveUris_.Clone();
      properties_ = other.properties_.Clone();
      LoggingConfig = other.loggingConfig_ != null ? other.LoggingConfig.Clone() : null;
      switch (other.DriverCase) {
        case DriverOneofCase.MainJarFileUri:
          MainJarFileUri = other.MainJarFileUri;
          break;
        case DriverOneofCase.MainClass:
          MainClass = other.MainClass;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SparkJob Clone() {
      return new SparkJob(this);
    }

    /// <summary>Field number for the "main_jar_file_uri" field.</summary>
    public const int MainJarFileUriFieldNumber = 1;
    /// <summary>
    ///  The HCFS URI of the jar file that contains the main class.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string MainJarFileUri {
      get { return driverCase_ == DriverOneofCase.MainJarFileUri ? (string) driver_ : ""; }
      set {
        driver_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        driverCase_ = DriverOneofCase.MainJarFileUri;
      }
    }

    /// <summary>Field number for the "main_class" field.</summary>
    public const int MainClassFieldNumber = 2;
    /// <summary>
    ///  The name of the driver's main class. The jar file that contains the class
    ///  must be in the default CLASSPATH or specified in `jar_file_uris`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string MainClass {
      get { return driverCase_ == DriverOneofCase.MainClass ? (string) driver_ : ""; }
      set {
        driver_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        driverCase_ = DriverOneofCase.MainClass;
      }
    }

    /// <summary>Field number for the "args" field.</summary>
    public const int ArgsFieldNumber = 3;
    private static readonly pb::FieldCodec<string> _repeated_args_codec
        = pb::FieldCodec.ForString(26);
    private readonly pbc::RepeatedField<string> args_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] The arguments to pass to the driver. Do not include arguments,
    ///  such as `--conf`, that can be set as job properties, since a collision may
    ///  occur that causes an incorrect job submission.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Args {
      get { return args_; }
    }

    /// <summary>Field number for the "jar_file_uris" field.</summary>
    public const int JarFileUrisFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_jarFileUris_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> jarFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of jar files to add to the CLASSPATHs of the
    ///  Spark driver and tasks.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> JarFileUris {
      get { return jarFileUris_; }
    }

    /// <summary>Field number for the "file_uris" field.</summary>
    public const int FileUrisFieldNumber = 5;
    private static readonly pb::FieldCodec<string> _repeated_fileUris_codec
        = pb::FieldCodec.ForString(42);
    private readonly pbc::RepeatedField<string> fileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of files to be copied to the working directory of
    ///  Spark drivers and distributed tasks. Useful for naively parallel tasks.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> FileUris {
      get { return fileUris_; }
    }

    /// <summary>Field number for the "archive_uris" field.</summary>
    public const int ArchiveUrisFieldNumber = 6;
    private static readonly pb::FieldCodec<string> _repeated_archiveUris_codec
        = pb::FieldCodec.ForString(50);
    private readonly pbc::RepeatedField<string> archiveUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of archives to be extracted in the working directory
    ///  of Spark drivers and tasks. Supported file types:
    ///  .jar, .tar, .tar.gz, .tgz, and .zip.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> ArchiveUris {
      get { return archiveUris_; }
    }

    /// <summary>Field number for the "properties" field.</summary>
    public const int PropertiesFieldNumber = 7;
    private static readonly pbc::MapField<string, string>.Codec _map_properties_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 58);
    private readonly pbc::MapField<string, string> properties_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] A mapping of property names to values, used to configure Spark.
    ///  Properties that conflict with values set by the Cloud Dataproc API may be
    ///  overwritten. Can include properties set in
    ///  /etc/spark/conf/spark-defaults.conf and classes in user code.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> Properties {
      get { return properties_; }
    }

    /// <summary>Field number for the "logging_config" field.</summary>
    public const int LoggingConfigFieldNumber = 8;
    private global::Google.Cloud.Dataproc.V1.LoggingConfig loggingConfig_;
    /// <summary>
    ///  [Optional] The runtime log config for job execution.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.LoggingConfig LoggingConfig {
      get { return loggingConfig_; }
      set {
        loggingConfig_ = value;
      }
    }

    private object driver_;
    /// <summary>Enum of possible cases for the "driver" oneof.</summary>
    public enum DriverOneofCase {
      None = 0,
      MainJarFileUri = 1,
      MainClass = 2,
    }
    private DriverOneofCase driverCase_ = DriverOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public DriverOneofCase DriverCase {
      get { return driverCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearDriver() {
      driverCase_ = DriverOneofCase.None;
      driver_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SparkJob);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SparkJob other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (MainJarFileUri != other.MainJarFileUri) return false;
      if (MainClass != other.MainClass) return false;
      if(!args_.Equals(other.args_)) return false;
      if(!jarFileUris_.Equals(other.jarFileUris_)) return false;
      if(!fileUris_.Equals(other.fileUris_)) return false;
      if(!archiveUris_.Equals(other.archiveUris_)) return false;
      if (!Properties.Equals(other.Properties)) return false;
      if (!object.Equals(LoggingConfig, other.LoggingConfig)) return false;
      if (DriverCase != other.DriverCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (driverCase_ == DriverOneofCase.MainJarFileUri) hash ^= MainJarFileUri.GetHashCode();
      if (driverCase_ == DriverOneofCase.MainClass) hash ^= MainClass.GetHashCode();
      hash ^= args_.GetHashCode();
      hash ^= jarFileUris_.GetHashCode();
      hash ^= fileUris_.GetHashCode();
      hash ^= archiveUris_.GetHashCode();
      hash ^= Properties.GetHashCode();
      if (loggingConfig_ != null) hash ^= LoggingConfig.GetHashCode();
      hash ^= (int) driverCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (driverCase_ == DriverOneofCase.MainJarFileUri) {
        output.WriteRawTag(10);
        output.WriteString(MainJarFileUri);
      }
      if (driverCase_ == DriverOneofCase.MainClass) {
        output.WriteRawTag(18);
        output.WriteString(MainClass);
      }
      args_.WriteTo(output, _repeated_args_codec);
      jarFileUris_.WriteTo(output, _repeated_jarFileUris_codec);
      fileUris_.WriteTo(output, _repeated_fileUris_codec);
      archiveUris_.WriteTo(output, _repeated_archiveUris_codec);
      properties_.WriteTo(output, _map_properties_codec);
      if (loggingConfig_ != null) {
        output.WriteRawTag(66);
        output.WriteMessage(LoggingConfig);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (driverCase_ == DriverOneofCase.MainJarFileUri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(MainJarFileUri);
      }
      if (driverCase_ == DriverOneofCase.MainClass) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(MainClass);
      }
      size += args_.CalculateSize(_repeated_args_codec);
      size += jarFileUris_.CalculateSize(_repeated_jarFileUris_codec);
      size += fileUris_.CalculateSize(_repeated_fileUris_codec);
      size += archiveUris_.CalculateSize(_repeated_archiveUris_codec);
      size += properties_.CalculateSize(_map_properties_codec);
      if (loggingConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(LoggingConfig);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SparkJob other) {
      if (other == null) {
        return;
      }
      args_.Add(other.args_);
      jarFileUris_.Add(other.jarFileUris_);
      fileUris_.Add(other.fileUris_);
      archiveUris_.Add(other.archiveUris_);
      properties_.Add(other.properties_);
      if (other.loggingConfig_ != null) {
        if (loggingConfig_ == null) {
          loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
        }
        LoggingConfig.MergeFrom(other.LoggingConfig);
      }
      switch (other.DriverCase) {
        case DriverOneofCase.MainJarFileUri:
          MainJarFileUri = other.MainJarFileUri;
          break;
        case DriverOneofCase.MainClass:
          MainClass = other.MainClass;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            MainJarFileUri = input.ReadString();
            break;
          }
          case 18: {
            MainClass = input.ReadString();
            break;
          }
          case 26: {
            args_.AddEntriesFrom(input, _repeated_args_codec);
            break;
          }
          case 34: {
            jarFileUris_.AddEntriesFrom(input, _repeated_jarFileUris_codec);
            break;
          }
          case 42: {
            fileUris_.AddEntriesFrom(input, _repeated_fileUris_codec);
            break;
          }
          case 50: {
            archiveUris_.AddEntriesFrom(input, _repeated_archiveUris_codec);
            break;
          }
          case 58: {
            properties_.AddEntriesFrom(input, _map_properties_codec);
            break;
          }
          case 66: {
            if (loggingConfig_ == null) {
              loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
            }
            input.ReadMessage(loggingConfig_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A Cloud Dataproc job for running
  ///  [Apache PySpark](https://spark.apache.org/docs/0.9.0/python-programming-guide.html)
  ///  applications on YARN.
  /// </summary>
  public sealed partial class PySparkJob : pb::IMessage<PySparkJob> {
    private static readonly pb::MessageParser<PySparkJob> _parser = new pb::MessageParser<PySparkJob>(() => new PySparkJob());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<PySparkJob> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public PySparkJob() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public PySparkJob(PySparkJob other) : this() {
      mainPythonFileUri_ = other.mainPythonFileUri_;
      args_ = other.args_.Clone();
      pythonFileUris_ = other.pythonFileUris_.Clone();
      jarFileUris_ = other.jarFileUris_.Clone();
      fileUris_ = other.fileUris_.Clone();
      archiveUris_ = other.archiveUris_.Clone();
      properties_ = other.properties_.Clone();
      LoggingConfig = other.loggingConfig_ != null ? other.LoggingConfig.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public PySparkJob Clone() {
      return new PySparkJob(this);
    }

    /// <summary>Field number for the "main_python_file_uri" field.</summary>
    public const int MainPythonFileUriFieldNumber = 1;
    private string mainPythonFileUri_ = "";
    /// <summary>
    ///  [Required] The HCFS URI of the main Python file to use as the driver. Must
    ///  be a .py file.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string MainPythonFileUri {
      get { return mainPythonFileUri_; }
      set {
        mainPythonFileUri_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "args" field.</summary>
    public const int ArgsFieldNumber = 2;
    private static readonly pb::FieldCodec<string> _repeated_args_codec
        = pb::FieldCodec.ForString(18);
    private readonly pbc::RepeatedField<string> args_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] The arguments to pass to the driver.  Do not include arguments,
    ///  such as `--conf`, that can be set as job properties, since a collision may
    ///  occur that causes an incorrect job submission.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Args {
      get { return args_; }
    }

    /// <summary>Field number for the "python_file_uris" field.</summary>
    public const int PythonFileUrisFieldNumber = 3;
    private static readonly pb::FieldCodec<string> _repeated_pythonFileUris_codec
        = pb::FieldCodec.ForString(26);
    private readonly pbc::RepeatedField<string> pythonFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS file URIs of Python files to pass to the PySpark
    ///  framework. Supported file types: .py, .egg, and .zip.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> PythonFileUris {
      get { return pythonFileUris_; }
    }

    /// <summary>Field number for the "jar_file_uris" field.</summary>
    public const int JarFileUrisFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_jarFileUris_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> jarFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of jar files to add to the CLASSPATHs of the
    ///  Python driver and tasks.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> JarFileUris {
      get { return jarFileUris_; }
    }

    /// <summary>Field number for the "file_uris" field.</summary>
    public const int FileUrisFieldNumber = 5;
    private static readonly pb::FieldCodec<string> _repeated_fileUris_codec
        = pb::FieldCodec.ForString(42);
    private readonly pbc::RepeatedField<string> fileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of files to be copied to the working directory of
    ///  Python drivers and distributed tasks. Useful for naively parallel tasks.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> FileUris {
      get { return fileUris_; }
    }

    /// <summary>Field number for the "archive_uris" field.</summary>
    public const int ArchiveUrisFieldNumber = 6;
    private static readonly pb::FieldCodec<string> _repeated_archiveUris_codec
        = pb::FieldCodec.ForString(50);
    private readonly pbc::RepeatedField<string> archiveUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of archives to be extracted in the working directory of
    ///  .jar, .tar, .tar.gz, .tgz, and .zip.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> ArchiveUris {
      get { return archiveUris_; }
    }

    /// <summary>Field number for the "properties" field.</summary>
    public const int PropertiesFieldNumber = 7;
    private static readonly pbc::MapField<string, string>.Codec _map_properties_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 58);
    private readonly pbc::MapField<string, string> properties_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] A mapping of property names to values, used to configure PySpark.
    ///  Properties that conflict with values set by the Cloud Dataproc API may be
    ///  overwritten. Can include properties set in
    ///  /etc/spark/conf/spark-defaults.conf and classes in user code.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> Properties {
      get { return properties_; }
    }

    /// <summary>Field number for the "logging_config" field.</summary>
    public const int LoggingConfigFieldNumber = 8;
    private global::Google.Cloud.Dataproc.V1.LoggingConfig loggingConfig_;
    /// <summary>
    ///  [Optional] The runtime log config for job execution.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.LoggingConfig LoggingConfig {
      get { return loggingConfig_; }
      set {
        loggingConfig_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as PySparkJob);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(PySparkJob other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (MainPythonFileUri != other.MainPythonFileUri) return false;
      if(!args_.Equals(other.args_)) return false;
      if(!pythonFileUris_.Equals(other.pythonFileUris_)) return false;
      if(!jarFileUris_.Equals(other.jarFileUris_)) return false;
      if(!fileUris_.Equals(other.fileUris_)) return false;
      if(!archiveUris_.Equals(other.archiveUris_)) return false;
      if (!Properties.Equals(other.Properties)) return false;
      if (!object.Equals(LoggingConfig, other.LoggingConfig)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (MainPythonFileUri.Length != 0) hash ^= MainPythonFileUri.GetHashCode();
      hash ^= args_.GetHashCode();
      hash ^= pythonFileUris_.GetHashCode();
      hash ^= jarFileUris_.GetHashCode();
      hash ^= fileUris_.GetHashCode();
      hash ^= archiveUris_.GetHashCode();
      hash ^= Properties.GetHashCode();
      if (loggingConfig_ != null) hash ^= LoggingConfig.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (MainPythonFileUri.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(MainPythonFileUri);
      }
      args_.WriteTo(output, _repeated_args_codec);
      pythonFileUris_.WriteTo(output, _repeated_pythonFileUris_codec);
      jarFileUris_.WriteTo(output, _repeated_jarFileUris_codec);
      fileUris_.WriteTo(output, _repeated_fileUris_codec);
      archiveUris_.WriteTo(output, _repeated_archiveUris_codec);
      properties_.WriteTo(output, _map_properties_codec);
      if (loggingConfig_ != null) {
        output.WriteRawTag(66);
        output.WriteMessage(LoggingConfig);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (MainPythonFileUri.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(MainPythonFileUri);
      }
      size += args_.CalculateSize(_repeated_args_codec);
      size += pythonFileUris_.CalculateSize(_repeated_pythonFileUris_codec);
      size += jarFileUris_.CalculateSize(_repeated_jarFileUris_codec);
      size += fileUris_.CalculateSize(_repeated_fileUris_codec);
      size += archiveUris_.CalculateSize(_repeated_archiveUris_codec);
      size += properties_.CalculateSize(_map_properties_codec);
      if (loggingConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(LoggingConfig);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(PySparkJob other) {
      if (other == null) {
        return;
      }
      if (other.MainPythonFileUri.Length != 0) {
        MainPythonFileUri = other.MainPythonFileUri;
      }
      args_.Add(other.args_);
      pythonFileUris_.Add(other.pythonFileUris_);
      jarFileUris_.Add(other.jarFileUris_);
      fileUris_.Add(other.fileUris_);
      archiveUris_.Add(other.archiveUris_);
      properties_.Add(other.properties_);
      if (other.loggingConfig_ != null) {
        if (loggingConfig_ == null) {
          loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
        }
        LoggingConfig.MergeFrom(other.LoggingConfig);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            MainPythonFileUri = input.ReadString();
            break;
          }
          case 18: {
            args_.AddEntriesFrom(input, _repeated_args_codec);
            break;
          }
          case 26: {
            pythonFileUris_.AddEntriesFrom(input, _repeated_pythonFileUris_codec);
            break;
          }
          case 34: {
            jarFileUris_.AddEntriesFrom(input, _repeated_jarFileUris_codec);
            break;
          }
          case 42: {
            fileUris_.AddEntriesFrom(input, _repeated_fileUris_codec);
            break;
          }
          case 50: {
            archiveUris_.AddEntriesFrom(input, _repeated_archiveUris_codec);
            break;
          }
          case 58: {
            properties_.AddEntriesFrom(input, _map_properties_codec);
            break;
          }
          case 66: {
            if (loggingConfig_ == null) {
              loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
            }
            input.ReadMessage(loggingConfig_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A list of queries to run on a cluster.
  /// </summary>
  public sealed partial class QueryList : pb::IMessage<QueryList> {
    private static readonly pb::MessageParser<QueryList> _parser = new pb::MessageParser<QueryList>(() => new QueryList());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<QueryList> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public QueryList() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public QueryList(QueryList other) : this() {
      queries_ = other.queries_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public QueryList Clone() {
      return new QueryList(this);
    }

    /// <summary>Field number for the "queries" field.</summary>
    public const int QueriesFieldNumber = 1;
    private static readonly pb::FieldCodec<string> _repeated_queries_codec
        = pb::FieldCodec.ForString(10);
    private readonly pbc::RepeatedField<string> queries_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Required] The queries to execute. You do not need to terminate a query
    ///  with a semicolon. Multiple queries can be specified in one string
    ///  by separating each with a semicolon. Here is an example of an Cloud
    ///  Dataproc API snippet that uses a QueryList to specify a HiveJob:
    ///
    ///      "hiveJob": {
    ///        "queryList": {
    ///          "queries": [
    ///            "query1",
    ///            "query2",
    ///            "query3;query4",
    ///          ]
    ///        }
    ///      }
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Queries {
      get { return queries_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as QueryList);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(QueryList other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!queries_.Equals(other.queries_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= queries_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      queries_.WriteTo(output, _repeated_queries_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += queries_.CalculateSize(_repeated_queries_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(QueryList other) {
      if (other == null) {
        return;
      }
      queries_.Add(other.queries_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            queries_.AddEntriesFrom(input, _repeated_queries_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A Cloud Dataproc job for running [Apache Hive](https://hive.apache.org/)
  ///  queries on YARN.
  /// </summary>
  public sealed partial class HiveJob : pb::IMessage<HiveJob> {
    private static readonly pb::MessageParser<HiveJob> _parser = new pb::MessageParser<HiveJob>(() => new HiveJob());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<HiveJob> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public HiveJob() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public HiveJob(HiveJob other) : this() {
      continueOnFailure_ = other.continueOnFailure_;
      scriptVariables_ = other.scriptVariables_.Clone();
      properties_ = other.properties_.Clone();
      jarFileUris_ = other.jarFileUris_.Clone();
      switch (other.QueriesCase) {
        case QueriesOneofCase.QueryFileUri:
          QueryFileUri = other.QueryFileUri;
          break;
        case QueriesOneofCase.QueryList:
          QueryList = other.QueryList.Clone();
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public HiveJob Clone() {
      return new HiveJob(this);
    }

    /// <summary>Field number for the "query_file_uri" field.</summary>
    public const int QueryFileUriFieldNumber = 1;
    /// <summary>
    ///  The HCFS URI of the script that contains Hive queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string QueryFileUri {
      get { return queriesCase_ == QueriesOneofCase.QueryFileUri ? (string) queries_ : ""; }
      set {
        queries_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        queriesCase_ = QueriesOneofCase.QueryFileUri;
      }
    }

    /// <summary>Field number for the "query_list" field.</summary>
    public const int QueryListFieldNumber = 2;
    /// <summary>
    ///  A list of queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.QueryList QueryList {
      get { return queriesCase_ == QueriesOneofCase.QueryList ? (global::Google.Cloud.Dataproc.V1.QueryList) queries_ : null; }
      set {
        queries_ = value;
        queriesCase_ = value == null ? QueriesOneofCase.None : QueriesOneofCase.QueryList;
      }
    }

    /// <summary>Field number for the "continue_on_failure" field.</summary>
    public const int ContinueOnFailureFieldNumber = 3;
    private bool continueOnFailure_;
    /// <summary>
    ///  [Optional] Whether to continue executing queries if a query fails.
    ///  The default value is `false`. Setting to `true` can be useful when executing
    ///  independent parallel queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ContinueOnFailure {
      get { return continueOnFailure_; }
      set {
        continueOnFailure_ = value;
      }
    }

    /// <summary>Field number for the "script_variables" field.</summary>
    public const int ScriptVariablesFieldNumber = 4;
    private static readonly pbc::MapField<string, string>.Codec _map_scriptVariables_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 34);
    private readonly pbc::MapField<string, string> scriptVariables_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] Mapping of query variable names to values (equivalent to the
    ///  Hive command: `SET name="value";`).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> ScriptVariables {
      get { return scriptVariables_; }
    }

    /// <summary>Field number for the "properties" field.</summary>
    public const int PropertiesFieldNumber = 5;
    private static readonly pbc::MapField<string, string>.Codec _map_properties_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 42);
    private readonly pbc::MapField<string, string> properties_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] A mapping of property names and values, used to configure Hive.
    ///  Properties that conflict with values set by the Cloud Dataproc API may be
    ///  overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml,
    ///  /etc/hive/conf/hive-site.xml, and classes in user code.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> Properties {
      get { return properties_; }
    }

    /// <summary>Field number for the "jar_file_uris" field.</summary>
    public const int JarFileUrisFieldNumber = 6;
    private static readonly pb::FieldCodec<string> _repeated_jarFileUris_codec
        = pb::FieldCodec.ForString(50);
    private readonly pbc::RepeatedField<string> jarFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of jar files to add to the CLASSPATH of the
    ///  Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes
    ///  and UDFs.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> JarFileUris {
      get { return jarFileUris_; }
    }

    private object queries_;
    /// <summary>Enum of possible cases for the "queries" oneof.</summary>
    public enum QueriesOneofCase {
      None = 0,
      QueryFileUri = 1,
      QueryList = 2,
    }
    private QueriesOneofCase queriesCase_ = QueriesOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public QueriesOneofCase QueriesCase {
      get { return queriesCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearQueries() {
      queriesCase_ = QueriesOneofCase.None;
      queries_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as HiveJob);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(HiveJob other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (QueryFileUri != other.QueryFileUri) return false;
      if (!object.Equals(QueryList, other.QueryList)) return false;
      if (ContinueOnFailure != other.ContinueOnFailure) return false;
      if (!ScriptVariables.Equals(other.ScriptVariables)) return false;
      if (!Properties.Equals(other.Properties)) return false;
      if(!jarFileUris_.Equals(other.jarFileUris_)) return false;
      if (QueriesCase != other.QueriesCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) hash ^= QueryFileUri.GetHashCode();
      if (queriesCase_ == QueriesOneofCase.QueryList) hash ^= QueryList.GetHashCode();
      if (ContinueOnFailure != false) hash ^= ContinueOnFailure.GetHashCode();
      hash ^= ScriptVariables.GetHashCode();
      hash ^= Properties.GetHashCode();
      hash ^= jarFileUris_.GetHashCode();
      hash ^= (int) queriesCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) {
        output.WriteRawTag(10);
        output.WriteString(QueryFileUri);
      }
      if (queriesCase_ == QueriesOneofCase.QueryList) {
        output.WriteRawTag(18);
        output.WriteMessage(QueryList);
      }
      if (ContinueOnFailure != false) {
        output.WriteRawTag(24);
        output.WriteBool(ContinueOnFailure);
      }
      scriptVariables_.WriteTo(output, _map_scriptVariables_codec);
      properties_.WriteTo(output, _map_properties_codec);
      jarFileUris_.WriteTo(output, _repeated_jarFileUris_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(QueryFileUri);
      }
      if (queriesCase_ == QueriesOneofCase.QueryList) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(QueryList);
      }
      if (ContinueOnFailure != false) {
        size += 1 + 1;
      }
      size += scriptVariables_.CalculateSize(_map_scriptVariables_codec);
      size += properties_.CalculateSize(_map_properties_codec);
      size += jarFileUris_.CalculateSize(_repeated_jarFileUris_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(HiveJob other) {
      if (other == null) {
        return;
      }
      if (other.ContinueOnFailure != false) {
        ContinueOnFailure = other.ContinueOnFailure;
      }
      scriptVariables_.Add(other.scriptVariables_);
      properties_.Add(other.properties_);
      jarFileUris_.Add(other.jarFileUris_);
      switch (other.QueriesCase) {
        case QueriesOneofCase.QueryFileUri:
          QueryFileUri = other.QueryFileUri;
          break;
        case QueriesOneofCase.QueryList:
          QueryList = other.QueryList;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            QueryFileUri = input.ReadString();
            break;
          }
          case 18: {
            global::Google.Cloud.Dataproc.V1.QueryList subBuilder = new global::Google.Cloud.Dataproc.V1.QueryList();
            if (queriesCase_ == QueriesOneofCase.QueryList) {
              subBuilder.MergeFrom(QueryList);
            }
            input.ReadMessage(subBuilder);
            QueryList = subBuilder;
            break;
          }
          case 24: {
            ContinueOnFailure = input.ReadBool();
            break;
          }
          case 34: {
            scriptVariables_.AddEntriesFrom(input, _map_scriptVariables_codec);
            break;
          }
          case 42: {
            properties_.AddEntriesFrom(input, _map_properties_codec);
            break;
          }
          case 50: {
            jarFileUris_.AddEntriesFrom(input, _repeated_jarFileUris_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A Cloud Dataproc job for running [Apache Spark SQL](http://spark.apache.org/sql/)
  ///  queries.
  /// </summary>
  public sealed partial class SparkSqlJob : pb::IMessage<SparkSqlJob> {
    private static readonly pb::MessageParser<SparkSqlJob> _parser = new pb::MessageParser<SparkSqlJob>(() => new SparkSqlJob());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SparkSqlJob> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SparkSqlJob() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SparkSqlJob(SparkSqlJob other) : this() {
      scriptVariables_ = other.scriptVariables_.Clone();
      properties_ = other.properties_.Clone();
      jarFileUris_ = other.jarFileUris_.Clone();
      LoggingConfig = other.loggingConfig_ != null ? other.LoggingConfig.Clone() : null;
      switch (other.QueriesCase) {
        case QueriesOneofCase.QueryFileUri:
          QueryFileUri = other.QueryFileUri;
          break;
        case QueriesOneofCase.QueryList:
          QueryList = other.QueryList.Clone();
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SparkSqlJob Clone() {
      return new SparkSqlJob(this);
    }

    /// <summary>Field number for the "query_file_uri" field.</summary>
    public const int QueryFileUriFieldNumber = 1;
    /// <summary>
    ///  The HCFS URI of the script that contains SQL queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string QueryFileUri {
      get { return queriesCase_ == QueriesOneofCase.QueryFileUri ? (string) queries_ : ""; }
      set {
        queries_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        queriesCase_ = QueriesOneofCase.QueryFileUri;
      }
    }

    /// <summary>Field number for the "query_list" field.</summary>
    public const int QueryListFieldNumber = 2;
    /// <summary>
    ///  A list of queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.QueryList QueryList {
      get { return queriesCase_ == QueriesOneofCase.QueryList ? (global::Google.Cloud.Dataproc.V1.QueryList) queries_ : null; }
      set {
        queries_ = value;
        queriesCase_ = value == null ? QueriesOneofCase.None : QueriesOneofCase.QueryList;
      }
    }

    /// <summary>Field number for the "script_variables" field.</summary>
    public const int ScriptVariablesFieldNumber = 3;
    private static readonly pbc::MapField<string, string>.Codec _map_scriptVariables_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 26);
    private readonly pbc::MapField<string, string> scriptVariables_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] Mapping of query variable names to values (equivalent to the
    ///  Spark SQL command: SET `name="value";`).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> ScriptVariables {
      get { return scriptVariables_; }
    }

    /// <summary>Field number for the "properties" field.</summary>
    public const int PropertiesFieldNumber = 4;
    private static readonly pbc::MapField<string, string>.Codec _map_properties_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 34);
    private readonly pbc::MapField<string, string> properties_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] A mapping of property names to values, used to configure
    ///  Spark SQL's SparkConf. Properties that conflict with values set by the
    ///  Cloud Dataproc API may be overwritten.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> Properties {
      get { return properties_; }
    }

    /// <summary>Field number for the "jar_file_uris" field.</summary>
    public const int JarFileUrisFieldNumber = 56;
    private static readonly pb::FieldCodec<string> _repeated_jarFileUris_codec
        = pb::FieldCodec.ForString(450);
    private readonly pbc::RepeatedField<string> jarFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of jar files to be added to the Spark CLASSPATH.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> JarFileUris {
      get { return jarFileUris_; }
    }

    /// <summary>Field number for the "logging_config" field.</summary>
    public const int LoggingConfigFieldNumber = 6;
    private global::Google.Cloud.Dataproc.V1.LoggingConfig loggingConfig_;
    /// <summary>
    ///  [Optional] The runtime log config for job execution.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.LoggingConfig LoggingConfig {
      get { return loggingConfig_; }
      set {
        loggingConfig_ = value;
      }
    }

    private object queries_;
    /// <summary>Enum of possible cases for the "queries" oneof.</summary>
    public enum QueriesOneofCase {
      None = 0,
      QueryFileUri = 1,
      QueryList = 2,
    }
    private QueriesOneofCase queriesCase_ = QueriesOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public QueriesOneofCase QueriesCase {
      get { return queriesCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearQueries() {
      queriesCase_ = QueriesOneofCase.None;
      queries_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SparkSqlJob);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SparkSqlJob other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (QueryFileUri != other.QueryFileUri) return false;
      if (!object.Equals(QueryList, other.QueryList)) return false;
      if (!ScriptVariables.Equals(other.ScriptVariables)) return false;
      if (!Properties.Equals(other.Properties)) return false;
      if(!jarFileUris_.Equals(other.jarFileUris_)) return false;
      if (!object.Equals(LoggingConfig, other.LoggingConfig)) return false;
      if (QueriesCase != other.QueriesCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) hash ^= QueryFileUri.GetHashCode();
      if (queriesCase_ == QueriesOneofCase.QueryList) hash ^= QueryList.GetHashCode();
      hash ^= ScriptVariables.GetHashCode();
      hash ^= Properties.GetHashCode();
      hash ^= jarFileUris_.GetHashCode();
      if (loggingConfig_ != null) hash ^= LoggingConfig.GetHashCode();
      hash ^= (int) queriesCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) {
        output.WriteRawTag(10);
        output.WriteString(QueryFileUri);
      }
      if (queriesCase_ == QueriesOneofCase.QueryList) {
        output.WriteRawTag(18);
        output.WriteMessage(QueryList);
      }
      scriptVariables_.WriteTo(output, _map_scriptVariables_codec);
      properties_.WriteTo(output, _map_properties_codec);
      if (loggingConfig_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(LoggingConfig);
      }
      jarFileUris_.WriteTo(output, _repeated_jarFileUris_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(QueryFileUri);
      }
      if (queriesCase_ == QueriesOneofCase.QueryList) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(QueryList);
      }
      size += scriptVariables_.CalculateSize(_map_scriptVariables_codec);
      size += properties_.CalculateSize(_map_properties_codec);
      size += jarFileUris_.CalculateSize(_repeated_jarFileUris_codec);
      if (loggingConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(LoggingConfig);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SparkSqlJob other) {
      if (other == null) {
        return;
      }
      scriptVariables_.Add(other.scriptVariables_);
      properties_.Add(other.properties_);
      jarFileUris_.Add(other.jarFileUris_);
      if (other.loggingConfig_ != null) {
        if (loggingConfig_ == null) {
          loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
        }
        LoggingConfig.MergeFrom(other.LoggingConfig);
      }
      switch (other.QueriesCase) {
        case QueriesOneofCase.QueryFileUri:
          QueryFileUri = other.QueryFileUri;
          break;
        case QueriesOneofCase.QueryList:
          QueryList = other.QueryList;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            QueryFileUri = input.ReadString();
            break;
          }
          case 18: {
            global::Google.Cloud.Dataproc.V1.QueryList subBuilder = new global::Google.Cloud.Dataproc.V1.QueryList();
            if (queriesCase_ == QueriesOneofCase.QueryList) {
              subBuilder.MergeFrom(QueryList);
            }
            input.ReadMessage(subBuilder);
            QueryList = subBuilder;
            break;
          }
          case 26: {
            scriptVariables_.AddEntriesFrom(input, _map_scriptVariables_codec);
            break;
          }
          case 34: {
            properties_.AddEntriesFrom(input, _map_properties_codec);
            break;
          }
          case 50: {
            if (loggingConfig_ == null) {
              loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
            }
            input.ReadMessage(loggingConfig_);
            break;
          }
          case 450: {
            jarFileUris_.AddEntriesFrom(input, _repeated_jarFileUris_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A Cloud Dataproc job for running [Apache Pig](https://pig.apache.org/)
  ///  queries on YARN.
  /// </summary>
  public sealed partial class PigJob : pb::IMessage<PigJob> {
    private static readonly pb::MessageParser<PigJob> _parser = new pb::MessageParser<PigJob>(() => new PigJob());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<PigJob> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[7]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public PigJob() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public PigJob(PigJob other) : this() {
      continueOnFailure_ = other.continueOnFailure_;
      scriptVariables_ = other.scriptVariables_.Clone();
      properties_ = other.properties_.Clone();
      jarFileUris_ = other.jarFileUris_.Clone();
      LoggingConfig = other.loggingConfig_ != null ? other.LoggingConfig.Clone() : null;
      switch (other.QueriesCase) {
        case QueriesOneofCase.QueryFileUri:
          QueryFileUri = other.QueryFileUri;
          break;
        case QueriesOneofCase.QueryList:
          QueryList = other.QueryList.Clone();
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public PigJob Clone() {
      return new PigJob(this);
    }

    /// <summary>Field number for the "query_file_uri" field.</summary>
    public const int QueryFileUriFieldNumber = 1;
    /// <summary>
    ///  The HCFS URI of the script that contains the Pig queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string QueryFileUri {
      get { return queriesCase_ == QueriesOneofCase.QueryFileUri ? (string) queries_ : ""; }
      set {
        queries_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        queriesCase_ = QueriesOneofCase.QueryFileUri;
      }
    }

    /// <summary>Field number for the "query_list" field.</summary>
    public const int QueryListFieldNumber = 2;
    /// <summary>
    ///  A list of queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.QueryList QueryList {
      get { return queriesCase_ == QueriesOneofCase.QueryList ? (global::Google.Cloud.Dataproc.V1.QueryList) queries_ : null; }
      set {
        queries_ = value;
        queriesCase_ = value == null ? QueriesOneofCase.None : QueriesOneofCase.QueryList;
      }
    }

    /// <summary>Field number for the "continue_on_failure" field.</summary>
    public const int ContinueOnFailureFieldNumber = 3;
    private bool continueOnFailure_;
    /// <summary>
    ///  [Optional] Whether to continue executing queries if a query fails.
    ///  The default value is `false`. Setting to `true` can be useful when executing
    ///  independent parallel queries.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ContinueOnFailure {
      get { return continueOnFailure_; }
      set {
        continueOnFailure_ = value;
      }
    }

    /// <summary>Field number for the "script_variables" field.</summary>
    public const int ScriptVariablesFieldNumber = 4;
    private static readonly pbc::MapField<string, string>.Codec _map_scriptVariables_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 34);
    private readonly pbc::MapField<string, string> scriptVariables_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] Mapping of query variable names to values (equivalent to the Pig
    ///  command: `name=[value]`).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> ScriptVariables {
      get { return scriptVariables_; }
    }

    /// <summary>Field number for the "properties" field.</summary>
    public const int PropertiesFieldNumber = 5;
    private static readonly pbc::MapField<string, string>.Codec _map_properties_codec
        = new pbc::MapField<string, string>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForString(18), 42);
    private readonly pbc::MapField<string, string> properties_ = new pbc::MapField<string, string>();
    /// <summary>
    ///  [Optional] A mapping of property names to values, used to configure Pig.
    ///  Properties that conflict with values set by the Cloud Dataproc API may be
    ///  overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml,
    ///  /etc/pig/conf/pig.properties, and classes in user code.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, string> Properties {
      get { return properties_; }
    }

    /// <summary>Field number for the "jar_file_uris" field.</summary>
    public const int JarFileUrisFieldNumber = 6;
    private static readonly pb::FieldCodec<string> _repeated_jarFileUris_codec
        = pb::FieldCodec.ForString(50);
    private readonly pbc::RepeatedField<string> jarFileUris_ = new pbc::RepeatedField<string>();
    /// <summary>
    ///  [Optional] HCFS URIs of jar files to add to the CLASSPATH of
    ///  the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> JarFileUris {
      get { return jarFileUris_; }
    }

    /// <summary>Field number for the "logging_config" field.</summary>
    public const int LoggingConfigFieldNumber = 7;
    private global::Google.Cloud.Dataproc.V1.LoggingConfig loggingConfig_;
    /// <summary>
    ///  [Optional] The runtime log config for job execution.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.LoggingConfig LoggingConfig {
      get { return loggingConfig_; }
      set {
        loggingConfig_ = value;
      }
    }

    private object queries_;
    /// <summary>Enum of possible cases for the "queries" oneof.</summary>
    public enum QueriesOneofCase {
      None = 0,
      QueryFileUri = 1,
      QueryList = 2,
    }
    private QueriesOneofCase queriesCase_ = QueriesOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public QueriesOneofCase QueriesCase {
      get { return queriesCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearQueries() {
      queriesCase_ = QueriesOneofCase.None;
      queries_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as PigJob);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(PigJob other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (QueryFileUri != other.QueryFileUri) return false;
      if (!object.Equals(QueryList, other.QueryList)) return false;
      if (ContinueOnFailure != other.ContinueOnFailure) return false;
      if (!ScriptVariables.Equals(other.ScriptVariables)) return false;
      if (!Properties.Equals(other.Properties)) return false;
      if(!jarFileUris_.Equals(other.jarFileUris_)) return false;
      if (!object.Equals(LoggingConfig, other.LoggingConfig)) return false;
      if (QueriesCase != other.QueriesCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) hash ^= QueryFileUri.GetHashCode();
      if (queriesCase_ == QueriesOneofCase.QueryList) hash ^= QueryList.GetHashCode();
      if (ContinueOnFailure != false) hash ^= ContinueOnFailure.GetHashCode();
      hash ^= ScriptVariables.GetHashCode();
      hash ^= Properties.GetHashCode();
      hash ^= jarFileUris_.GetHashCode();
      if (loggingConfig_ != null) hash ^= LoggingConfig.GetHashCode();
      hash ^= (int) queriesCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) {
        output.WriteRawTag(10);
        output.WriteString(QueryFileUri);
      }
      if (queriesCase_ == QueriesOneofCase.QueryList) {
        output.WriteRawTag(18);
        output.WriteMessage(QueryList);
      }
      if (ContinueOnFailure != false) {
        output.WriteRawTag(24);
        output.WriteBool(ContinueOnFailure);
      }
      scriptVariables_.WriteTo(output, _map_scriptVariables_codec);
      properties_.WriteTo(output, _map_properties_codec);
      jarFileUris_.WriteTo(output, _repeated_jarFileUris_codec);
      if (loggingConfig_ != null) {
        output.WriteRawTag(58);
        output.WriteMessage(LoggingConfig);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (queriesCase_ == QueriesOneofCase.QueryFileUri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(QueryFileUri);
      }
      if (queriesCase_ == QueriesOneofCase.QueryList) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(QueryList);
      }
      if (ContinueOnFailure != false) {
        size += 1 + 1;
      }
      size += scriptVariables_.CalculateSize(_map_scriptVariables_codec);
      size += properties_.CalculateSize(_map_properties_codec);
      size += jarFileUris_.CalculateSize(_repeated_jarFileUris_codec);
      if (loggingConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(LoggingConfig);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(PigJob other) {
      if (other == null) {
        return;
      }
      if (other.ContinueOnFailure != false) {
        ContinueOnFailure = other.ContinueOnFailure;
      }
      scriptVariables_.Add(other.scriptVariables_);
      properties_.Add(other.properties_);
      jarFileUris_.Add(other.jarFileUris_);
      if (other.loggingConfig_ != null) {
        if (loggingConfig_ == null) {
          loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
        }
        LoggingConfig.MergeFrom(other.LoggingConfig);
      }
      switch (other.QueriesCase) {
        case QueriesOneofCase.QueryFileUri:
          QueryFileUri = other.QueryFileUri;
          break;
        case QueriesOneofCase.QueryList:
          QueryList = other.QueryList;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            QueryFileUri = input.ReadString();
            break;
          }
          case 18: {
            global::Google.Cloud.Dataproc.V1.QueryList subBuilder = new global::Google.Cloud.Dataproc.V1.QueryList();
            if (queriesCase_ == QueriesOneofCase.QueryList) {
              subBuilder.MergeFrom(QueryList);
            }
            input.ReadMessage(subBuilder);
            QueryList = subBuilder;
            break;
          }
          case 24: {
            ContinueOnFailure = input.ReadBool();
            break;
          }
          case 34: {
            scriptVariables_.AddEntriesFrom(input, _map_scriptVariables_codec);
            break;
          }
          case 42: {
            properties_.AddEntriesFrom(input, _map_properties_codec);
            break;
          }
          case 50: {
            jarFileUris_.AddEntriesFrom(input, _repeated_jarFileUris_codec);
            break;
          }
          case 58: {
            if (loggingConfig_ == null) {
              loggingConfig_ = new global::Google.Cloud.Dataproc.V1.LoggingConfig();
            }
            input.ReadMessage(loggingConfig_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  Cloud Dataproc job config.
  /// </summary>
  public sealed partial class JobPlacement : pb::IMessage<JobPlacement> {
    private static readonly pb::MessageParser<JobPlacement> _parser = new pb::MessageParser<JobPlacement>(() => new JobPlacement());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<JobPlacement> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[8]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobPlacement() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobPlacement(JobPlacement other) : this() {
      clusterName_ = other.clusterName_;
      clusterUuid_ = other.clusterUuid_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobPlacement Clone() {
      return new JobPlacement(this);
    }

    /// <summary>Field number for the "cluster_name" field.</summary>
    public const int ClusterNameFieldNumber = 1;
    private string clusterName_ = "";
    /// <summary>
    ///  [Required] The name of the cluster where the job will be submitted.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ClusterName {
      get { return clusterName_; }
      set {
        clusterName_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "cluster_uuid" field.</summary>
    public const int ClusterUuidFieldNumber = 2;
    private string clusterUuid_ = "";
    /// <summary>
    ///  [Output-only] A cluster UUID generated by the Cloud Dataproc service when
    ///  the job is submitted.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ClusterUuid {
      get { return clusterUuid_; }
      set {
        clusterUuid_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as JobPlacement);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(JobPlacement other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ClusterName != other.ClusterName) return false;
      if (ClusterUuid != other.ClusterUuid) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ClusterName.Length != 0) hash ^= ClusterName.GetHashCode();
      if (ClusterUuid.Length != 0) hash ^= ClusterUuid.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ClusterName.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ClusterName);
      }
      if (ClusterUuid.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(ClusterUuid);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ClusterName.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ClusterName);
      }
      if (ClusterUuid.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ClusterUuid);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(JobPlacement other) {
      if (other == null) {
        return;
      }
      if (other.ClusterName.Length != 0) {
        ClusterName = other.ClusterName;
      }
      if (other.ClusterUuid.Length != 0) {
        ClusterUuid = other.ClusterUuid;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ClusterName = input.ReadString();
            break;
          }
          case 18: {
            ClusterUuid = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  Cloud Dataproc job status.
  /// </summary>
  public sealed partial class JobStatus : pb::IMessage<JobStatus> {
    private static readonly pb::MessageParser<JobStatus> _parser = new pb::MessageParser<JobStatus>(() => new JobStatus());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<JobStatus> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[9]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobStatus() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobStatus(JobStatus other) : this() {
      state_ = other.state_;
      details_ = other.details_;
      StateStartTime = other.stateStartTime_ != null ? other.StateStartTime.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobStatus Clone() {
      return new JobStatus(this);
    }

    /// <summary>Field number for the "state" field.</summary>
    public const int StateFieldNumber = 1;
    private global::Google.Cloud.Dataproc.V1.JobStatus.Types.State state_ = 0;
    /// <summary>
    ///  [Output-only] A state message specifying the overall job state.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.JobStatus.Types.State State {
      get { return state_; }
      set {
        state_ = value;
      }
    }

    /// <summary>Field number for the "details" field.</summary>
    public const int DetailsFieldNumber = 2;
    private string details_ = "";
    /// <summary>
    ///  [Output-only] Optional job state details, such as an error
    ///  description if the state is &lt;code>ERROR&lt;/code>.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Details {
      get { return details_; }
      set {
        details_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "state_start_time" field.</summary>
    public const int StateStartTimeFieldNumber = 6;
    private global::Google.Protobuf.WellKnownTypes.Timestamp stateStartTime_;
    /// <summary>
    ///  [Output-only] The time when this state was entered.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Timestamp StateStartTime {
      get { return stateStartTime_; }
      set {
        stateStartTime_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as JobStatus);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(JobStatus other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (State != other.State) return false;
      if (Details != other.Details) return false;
      if (!object.Equals(StateStartTime, other.StateStartTime)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (State != 0) hash ^= State.GetHashCode();
      if (Details.Length != 0) hash ^= Details.GetHashCode();
      if (stateStartTime_ != null) hash ^= StateStartTime.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (State != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) State);
      }
      if (Details.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(Details);
      }
      if (stateStartTime_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(StateStartTime);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (State != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) State);
      }
      if (Details.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Details);
      }
      if (stateStartTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StateStartTime);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(JobStatus other) {
      if (other == null) {
        return;
      }
      if (other.State != 0) {
        State = other.State;
      }
      if (other.Details.Length != 0) {
        Details = other.Details;
      }
      if (other.stateStartTime_ != null) {
        if (stateStartTime_ == null) {
          stateStartTime_ = new global::Google.Protobuf.WellKnownTypes.Timestamp();
        }
        StateStartTime.MergeFrom(other.StateStartTime);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            state_ = (global::Google.Cloud.Dataproc.V1.JobStatus.Types.State) input.ReadEnum();
            break;
          }
          case 18: {
            Details = input.ReadString();
            break;
          }
          case 50: {
            if (stateStartTime_ == null) {
              stateStartTime_ = new global::Google.Protobuf.WellKnownTypes.Timestamp();
            }
            input.ReadMessage(stateStartTime_);
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the JobStatus message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      ///  The job state.
      /// </summary>
      public enum State {
        /// <summary>
        ///  The job state is unknown.
        /// </summary>
        [pbr::OriginalName("STATE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        ///  The job is pending; it has been submitted, but is not yet running.
        /// </summary>
        [pbr::OriginalName("PENDING")] Pending = 1,
        /// <summary>
        ///  Job has been received by the service and completed initial setup;
        ///  it will soon be submitted to the cluster.
        /// </summary>
        [pbr::OriginalName("SETUP_DONE")] SetupDone = 8,
        /// <summary>
        ///  The job is running on the cluster.
        /// </summary>
        [pbr::OriginalName("RUNNING")] Running = 2,
        /// <summary>
        ///  A CancelJob request has been received, but is pending.
        /// </summary>
        [pbr::OriginalName("CANCEL_PENDING")] CancelPending = 3,
        /// <summary>
        ///  Transient in-flight resources have been canceled, and the request to
        ///  cancel the running job has been issued to the cluster.
        /// </summary>
        [pbr::OriginalName("CANCEL_STARTED")] CancelStarted = 7,
        /// <summary>
        ///  The job cancellation was successful.
        /// </summary>
        [pbr::OriginalName("CANCELLED")] Cancelled = 4,
        /// <summary>
        ///  The job has completed successfully.
        /// </summary>
        [pbr::OriginalName("DONE")] Done = 5,
        /// <summary>
        ///  The job has completed, but encountered an error.
        /// </summary>
        [pbr::OriginalName("ERROR")] Error = 6,
      }

    }
    #endregion

  }

  /// <summary>
  ///  Encapsulates the full scoping used to reference a job.
  /// </summary>
  public sealed partial class JobReference : pb::IMessage<JobReference> {
    private static readonly pb::MessageParser<JobReference> _parser = new pb::MessageParser<JobReference>(() => new JobReference());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<JobReference> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[10]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobReference() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobReference(JobReference other) : this() {
      projectId_ = other.projectId_;
      jobId_ = other.jobId_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public JobReference Clone() {
      return new JobReference(this);
    }

    /// <summary>Field number for the "project_id" field.</summary>
    public const int ProjectIdFieldNumber = 1;
    private string projectId_ = "";
    /// <summary>
    ///  [Required] The ID of the Google Cloud Platform project that the job
    ///  belongs to.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ProjectId {
      get { return projectId_; }
      set {
        projectId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "job_id" field.</summary>
    public const int JobIdFieldNumber = 2;
    private string jobId_ = "";
    /// <summary>
    ///  [Optional] The job ID, which must be unique within the project. The job ID
    ///  is generated by the server upon job submission or provided by the user as a
    ///  means to perform retries without creating duplicate jobs. The ID must
    ///  contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or
    ///  hyphens (-). The maximum length is 512 characters.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string JobId {
      get { return jobId_; }
      set {
        jobId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as JobReference);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(JobReference other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProjectId != other.ProjectId) return false;
      if (JobId != other.JobId) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProjectId.Length != 0) hash ^= ProjectId.GetHashCode();
      if (JobId.Length != 0) hash ^= JobId.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ProjectId.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ProjectId);
      }
      if (JobId.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(JobId);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProjectId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ProjectId);
      }
      if (JobId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(JobId);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(JobReference other) {
      if (other == null) {
        return;
      }
      if (other.ProjectId.Length != 0) {
        ProjectId = other.ProjectId;
      }
      if (other.JobId.Length != 0) {
        JobId = other.JobId;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ProjectId = input.ReadString();
            break;
          }
          case 18: {
            JobId = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A Cloud Dataproc job resource.
  /// </summary>
  public sealed partial class Job : pb::IMessage<Job> {
    private static readonly pb::MessageParser<Job> _parser = new pb::MessageParser<Job>(() => new Job());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<Job> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[11]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public Job() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public Job(Job other) : this() {
      Reference = other.reference_ != null ? other.Reference.Clone() : null;
      Placement = other.placement_ != null ? other.Placement.Clone() : null;
      Status = other.status_ != null ? other.Status.Clone() : null;
      statusHistory_ = other.statusHistory_.Clone();
      driverOutputResourceUri_ = other.driverOutputResourceUri_;
      driverControlFilesUri_ = other.driverControlFilesUri_;
      switch (other.TypeJobCase) {
        case TypeJobOneofCase.HadoopJob:
          HadoopJob = other.HadoopJob.Clone();
          break;
        case TypeJobOneofCase.SparkJob:
          SparkJob = other.SparkJob.Clone();
          break;
        case TypeJobOneofCase.PysparkJob:
          PysparkJob = other.PysparkJob.Clone();
          break;
        case TypeJobOneofCase.HiveJob:
          HiveJob = other.HiveJob.Clone();
          break;
        case TypeJobOneofCase.PigJob:
          PigJob = other.PigJob.Clone();
          break;
        case TypeJobOneofCase.SparkSqlJob:
          SparkSqlJob = other.SparkSqlJob.Clone();
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public Job Clone() {
      return new Job(this);
    }

    /// <summary>Field number for the "reference" field.</summary>
    public const int ReferenceFieldNumber = 1;
    private global::Google.Cloud.Dataproc.V1.JobReference reference_;
    /// <summary>
    ///  [Optional] The fully qualified reference to the job, which can be used to
    ///  obtain the equivalent REST path of the job resource. If this property
    ///  is not specified when a job is created, the server generates a
    ///  &lt;code>job_id&lt;/code>.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.JobReference Reference {
      get { return reference_; }
      set {
        reference_ = value;
      }
    }

    /// <summary>Field number for the "placement" field.</summary>
    public const int PlacementFieldNumber = 2;
    private global::Google.Cloud.Dataproc.V1.JobPlacement placement_;
    /// <summary>
    ///  [Required] Job information, including how, when, and where to
    ///  run the job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.JobPlacement Placement {
      get { return placement_; }
      set {
        placement_ = value;
      }
    }

    /// <summary>Field number for the "hadoop_job" field.</summary>
    public const int HadoopJobFieldNumber = 3;
    /// <summary>
    ///  Job is a Hadoop job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.HadoopJob HadoopJob {
      get { return typeJobCase_ == TypeJobOneofCase.HadoopJob ? (global::Google.Cloud.Dataproc.V1.HadoopJob) typeJob_ : null; }
      set {
        typeJob_ = value;
        typeJobCase_ = value == null ? TypeJobOneofCase.None : TypeJobOneofCase.HadoopJob;
      }
    }

    /// <summary>Field number for the "spark_job" field.</summary>
    public const int SparkJobFieldNumber = 4;
    /// <summary>
    ///  Job is a Spark job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.SparkJob SparkJob {
      get { return typeJobCase_ == TypeJobOneofCase.SparkJob ? (global::Google.Cloud.Dataproc.V1.SparkJob) typeJob_ : null; }
      set {
        typeJob_ = value;
        typeJobCase_ = value == null ? TypeJobOneofCase.None : TypeJobOneofCase.SparkJob;
      }
    }

    /// <summary>Field number for the "pyspark_job" field.</summary>
    public const int PysparkJobFieldNumber = 5;
    /// <summary>
    ///  Job is a Pyspark job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.PySparkJob PysparkJob {
      get { return typeJobCase_ == TypeJobOneofCase.PysparkJob ? (global::Google.Cloud.Dataproc.V1.PySparkJob) typeJob_ : null; }
      set {
        typeJob_ = value;
        typeJobCase_ = value == null ? TypeJobOneofCase.None : TypeJobOneofCase.PysparkJob;
      }
    }

    /// <summary>Field number for the "hive_job" field.</summary>
    public const int HiveJobFieldNumber = 6;
    /// <summary>
    ///  Job is a Hive job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.HiveJob HiveJob {
      get { return typeJobCase_ == TypeJobOneofCase.HiveJob ? (global::Google.Cloud.Dataproc.V1.HiveJob) typeJob_ : null; }
      set {
        typeJob_ = value;
        typeJobCase_ = value == null ? TypeJobOneofCase.None : TypeJobOneofCase.HiveJob;
      }
    }

    /// <summary>Field number for the "pig_job" field.</summary>
    public const int PigJobFieldNumber = 7;
    /// <summary>
    ///  Job is a Pig job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.PigJob PigJob {
      get { return typeJobCase_ == TypeJobOneofCase.PigJob ? (global::Google.Cloud.Dataproc.V1.PigJob) typeJob_ : null; }
      set {
        typeJob_ = value;
        typeJobCase_ = value == null ? TypeJobOneofCase.None : TypeJobOneofCase.PigJob;
      }
    }

    /// <summary>Field number for the "spark_sql_job" field.</summary>
    public const int SparkSqlJobFieldNumber = 12;
    /// <summary>
    ///  Job is a SparkSql job.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.SparkSqlJob SparkSqlJob {
      get { return typeJobCase_ == TypeJobOneofCase.SparkSqlJob ? (global::Google.Cloud.Dataproc.V1.SparkSqlJob) typeJob_ : null; }
      set {
        typeJob_ = value;
        typeJobCase_ = value == null ? TypeJobOneofCase.None : TypeJobOneofCase.SparkSqlJob;
      }
    }

    /// <summary>Field number for the "status" field.</summary>
    public const int StatusFieldNumber = 8;
    private global::Google.Cloud.Dataproc.V1.JobStatus status_;
    /// <summary>
    ///  [Output-only] The job status. Additional application-specific
    ///  status information may be contained in the &lt;code>type_job&lt;/code>
    ///  and &lt;code>yarn_applications&lt;/code> fields.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.JobStatus Status {
      get { return status_; }
      set {
        status_ = value;
      }
    }

    /// <summary>Field number for the "status_history" field.</summary>
    public const int StatusHistoryFieldNumber = 13;
    private static readonly pb::FieldCodec<global::Google.Cloud.Dataproc.V1.JobStatus> _repeated_statusHistory_codec
        = pb::FieldCodec.ForMessage(106, global::Google.Cloud.Dataproc.V1.JobStatus.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Dataproc.V1.JobStatus> statusHistory_ = new pbc::RepeatedField<global::Google.Cloud.Dataproc.V1.JobStatus>();
    /// <summary>
    ///  [Output-only] The previous job status.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Dataproc.V1.JobStatus> StatusHistory {
      get { return statusHistory_; }
    }

    /// <summary>Field number for the "driver_output_resource_uri" field.</summary>
    public const int DriverOutputResourceUriFieldNumber = 17;
    private string driverOutputResourceUri_ = "";
    /// <summary>
    ///  [Output-only] A URI pointing to the location of the stdout of the job's
    ///  driver program.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string DriverOutputResourceUri {
      get { return driverOutputResourceUri_; }
      set {
        driverOutputResourceUri_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "driver_control_files_uri" field.</summary>
    public const int DriverControlFilesUriFieldNumber = 15;
    private string driverControlFilesUri_ = "";
    /// <summary>
    ///  [Output-only] If present, the location of miscellaneous control files
    ///  which may be used as part of job setup and handling. If not present,
    ///  control files may be placed in the same location as `driver_output_uri`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string DriverControlFilesUri {
      get { return driverControlFilesUri_; }
      set {
        driverControlFilesUri_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    private object typeJob_;
    /// <summary>Enum of possible cases for the "type_job" oneof.</summary>
    public enum TypeJobOneofCase {
      None = 0,
      HadoopJob = 3,
      SparkJob = 4,
      PysparkJob = 5,
      HiveJob = 6,
      PigJob = 7,
      SparkSqlJob = 12,
    }
    private TypeJobOneofCase typeJobCase_ = TypeJobOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public TypeJobOneofCase TypeJobCase {
      get { return typeJobCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearTypeJob() {
      typeJobCase_ = TypeJobOneofCase.None;
      typeJob_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as Job);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(Job other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Reference, other.Reference)) return false;
      if (!object.Equals(Placement, other.Placement)) return false;
      if (!object.Equals(HadoopJob, other.HadoopJob)) return false;
      if (!object.Equals(SparkJob, other.SparkJob)) return false;
      if (!object.Equals(PysparkJob, other.PysparkJob)) return false;
      if (!object.Equals(HiveJob, other.HiveJob)) return false;
      if (!object.Equals(PigJob, other.PigJob)) return false;
      if (!object.Equals(SparkSqlJob, other.SparkSqlJob)) return false;
      if (!object.Equals(Status, other.Status)) return false;
      if(!statusHistory_.Equals(other.statusHistory_)) return false;
      if (DriverOutputResourceUri != other.DriverOutputResourceUri) return false;
      if (DriverControlFilesUri != other.DriverControlFilesUri) return false;
      if (TypeJobCase != other.TypeJobCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (reference_ != null) hash ^= Reference.GetHashCode();
      if (placement_ != null) hash ^= Placement.GetHashCode();
      if (typeJobCase_ == TypeJobOneofCase.HadoopJob) hash ^= HadoopJob.GetHashCode();
      if (typeJobCase_ == TypeJobOneofCase.SparkJob) hash ^= SparkJob.GetHashCode();
      if (typeJobCase_ == TypeJobOneofCase.PysparkJob) hash ^= PysparkJob.GetHashCode();
      if (typeJobCase_ == TypeJobOneofCase.HiveJob) hash ^= HiveJob.GetHashCode();
      if (typeJobCase_ == TypeJobOneofCase.PigJob) hash ^= PigJob.GetHashCode();
      if (typeJobCase_ == TypeJobOneofCase.SparkSqlJob) hash ^= SparkSqlJob.GetHashCode();
      if (status_ != null) hash ^= Status.GetHashCode();
      hash ^= statusHistory_.GetHashCode();
      if (DriverOutputResourceUri.Length != 0) hash ^= DriverOutputResourceUri.GetHashCode();
      if (DriverControlFilesUri.Length != 0) hash ^= DriverControlFilesUri.GetHashCode();
      hash ^= (int) typeJobCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (reference_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Reference);
      }
      if (placement_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Placement);
      }
      if (typeJobCase_ == TypeJobOneofCase.HadoopJob) {
        output.WriteRawTag(26);
        output.WriteMessage(HadoopJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.SparkJob) {
        output.WriteRawTag(34);
        output.WriteMessage(SparkJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.PysparkJob) {
        output.WriteRawTag(42);
        output.WriteMessage(PysparkJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.HiveJob) {
        output.WriteRawTag(50);
        output.WriteMessage(HiveJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.PigJob) {
        output.WriteRawTag(58);
        output.WriteMessage(PigJob);
      }
      if (status_ != null) {
        output.WriteRawTag(66);
        output.WriteMessage(Status);
      }
      if (typeJobCase_ == TypeJobOneofCase.SparkSqlJob) {
        output.WriteRawTag(98);
        output.WriteMessage(SparkSqlJob);
      }
      statusHistory_.WriteTo(output, _repeated_statusHistory_codec);
      if (DriverControlFilesUri.Length != 0) {
        output.WriteRawTag(122);
        output.WriteString(DriverControlFilesUri);
      }
      if (DriverOutputResourceUri.Length != 0) {
        output.WriteRawTag(138, 1);
        output.WriteString(DriverOutputResourceUri);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (reference_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Reference);
      }
      if (placement_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Placement);
      }
      if (typeJobCase_ == TypeJobOneofCase.HadoopJob) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(HadoopJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.SparkJob) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(SparkJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.PysparkJob) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(PysparkJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.HiveJob) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(HiveJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.PigJob) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(PigJob);
      }
      if (typeJobCase_ == TypeJobOneofCase.SparkSqlJob) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(SparkSqlJob);
      }
      if (status_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Status);
      }
      size += statusHistory_.CalculateSize(_repeated_statusHistory_codec);
      if (DriverOutputResourceUri.Length != 0) {
        size += 2 + pb::CodedOutputStream.ComputeStringSize(DriverOutputResourceUri);
      }
      if (DriverControlFilesUri.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(DriverControlFilesUri);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(Job other) {
      if (other == null) {
        return;
      }
      if (other.reference_ != null) {
        if (reference_ == null) {
          reference_ = new global::Google.Cloud.Dataproc.V1.JobReference();
        }
        Reference.MergeFrom(other.Reference);
      }
      if (other.placement_ != null) {
        if (placement_ == null) {
          placement_ = new global::Google.Cloud.Dataproc.V1.JobPlacement();
        }
        Placement.MergeFrom(other.Placement);
      }
      if (other.status_ != null) {
        if (status_ == null) {
          status_ = new global::Google.Cloud.Dataproc.V1.JobStatus();
        }
        Status.MergeFrom(other.Status);
      }
      statusHistory_.Add(other.statusHistory_);
      if (other.DriverOutputResourceUri.Length != 0) {
        DriverOutputResourceUri = other.DriverOutputResourceUri;
      }
      if (other.DriverControlFilesUri.Length != 0) {
        DriverControlFilesUri = other.DriverControlFilesUri;
      }
      switch (other.TypeJobCase) {
        case TypeJobOneofCase.HadoopJob:
          HadoopJob = other.HadoopJob;
          break;
        case TypeJobOneofCase.SparkJob:
          SparkJob = other.SparkJob;
          break;
        case TypeJobOneofCase.PysparkJob:
          PysparkJob = other.PysparkJob;
          break;
        case TypeJobOneofCase.HiveJob:
          HiveJob = other.HiveJob;
          break;
        case TypeJobOneofCase.PigJob:
          PigJob = other.PigJob;
          break;
        case TypeJobOneofCase.SparkSqlJob:
          SparkSqlJob = other.SparkSqlJob;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (reference_ == null) {
              reference_ = new global::Google.Cloud.Dataproc.V1.JobReference();
            }
            input.ReadMessage(reference_);
            break;
          }
          case 18: {
            if (placement_ == null) {
              placement_ = new global::Google.Cloud.Dataproc.V1.JobPlacement();
            }
            input.ReadMessage(placement_);
            break;
          }
          case 26: {
            global::Google.Cloud.Dataproc.V1.HadoopJob subBuilder = new global::Google.Cloud.Dataproc.V1.HadoopJob();
            if (typeJobCase_ == TypeJobOneofCase.HadoopJob) {
              subBuilder.MergeFrom(HadoopJob);
            }
            input.ReadMessage(subBuilder);
            HadoopJob = subBuilder;
            break;
          }
          case 34: {
            global::Google.Cloud.Dataproc.V1.SparkJob subBuilder = new global::Google.Cloud.Dataproc.V1.SparkJob();
            if (typeJobCase_ == TypeJobOneofCase.SparkJob) {
              subBuilder.MergeFrom(SparkJob);
            }
            input.ReadMessage(subBuilder);
            SparkJob = subBuilder;
            break;
          }
          case 42: {
            global::Google.Cloud.Dataproc.V1.PySparkJob subBuilder = new global::Google.Cloud.Dataproc.V1.PySparkJob();
            if (typeJobCase_ == TypeJobOneofCase.PysparkJob) {
              subBuilder.MergeFrom(PysparkJob);
            }
            input.ReadMessage(subBuilder);
            PysparkJob = subBuilder;
            break;
          }
          case 50: {
            global::Google.Cloud.Dataproc.V1.HiveJob subBuilder = new global::Google.Cloud.Dataproc.V1.HiveJob();
            if (typeJobCase_ == TypeJobOneofCase.HiveJob) {
              subBuilder.MergeFrom(HiveJob);
            }
            input.ReadMessage(subBuilder);
            HiveJob = subBuilder;
            break;
          }
          case 58: {
            global::Google.Cloud.Dataproc.V1.PigJob subBuilder = new global::Google.Cloud.Dataproc.V1.PigJob();
            if (typeJobCase_ == TypeJobOneofCase.PigJob) {
              subBuilder.MergeFrom(PigJob);
            }
            input.ReadMessage(subBuilder);
            PigJob = subBuilder;
            break;
          }
          case 66: {
            if (status_ == null) {
              status_ = new global::Google.Cloud.Dataproc.V1.JobStatus();
            }
            input.ReadMessage(status_);
            break;
          }
          case 98: {
            global::Google.Cloud.Dataproc.V1.SparkSqlJob subBuilder = new global::Google.Cloud.Dataproc.V1.SparkSqlJob();
            if (typeJobCase_ == TypeJobOneofCase.SparkSqlJob) {
              subBuilder.MergeFrom(SparkSqlJob);
            }
            input.ReadMessage(subBuilder);
            SparkSqlJob = subBuilder;
            break;
          }
          case 106: {
            statusHistory_.AddEntriesFrom(input, _repeated_statusHistory_codec);
            break;
          }
          case 122: {
            DriverControlFilesUri = input.ReadString();
            break;
          }
          case 138: {
            DriverOutputResourceUri = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A request to submit a job.
  /// </summary>
  public sealed partial class SubmitJobRequest : pb::IMessage<SubmitJobRequest> {
    private static readonly pb::MessageParser<SubmitJobRequest> _parser = new pb::MessageParser<SubmitJobRequest>(() => new SubmitJobRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SubmitJobRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[12]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SubmitJobRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SubmitJobRequest(SubmitJobRequest other) : this() {
      projectId_ = other.projectId_;
      region_ = other.region_;
      Job = other.job_ != null ? other.Job.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SubmitJobRequest Clone() {
      return new SubmitJobRequest(this);
    }

    /// <summary>Field number for the "project_id" field.</summary>
    public const int ProjectIdFieldNumber = 1;
    private string projectId_ = "";
    /// <summary>
    ///  [Required] The ID of the Google Cloud Platform project that the job
    ///  belongs to.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ProjectId {
      get { return projectId_; }
      set {
        projectId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "region" field.</summary>
    public const int RegionFieldNumber = 3;
    private string region_ = "";
    /// <summary>
    ///  [Required] The Cloud Dataproc region in which to handle the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Region {
      get { return region_; }
      set {
        region_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "job" field.</summary>
    public const int JobFieldNumber = 2;
    private global::Google.Cloud.Dataproc.V1.Job job_;
    /// <summary>
    ///  [Required] The job resource.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.Job Job {
      get { return job_; }
      set {
        job_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SubmitJobRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SubmitJobRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProjectId != other.ProjectId) return false;
      if (Region != other.Region) return false;
      if (!object.Equals(Job, other.Job)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProjectId.Length != 0) hash ^= ProjectId.GetHashCode();
      if (Region.Length != 0) hash ^= Region.GetHashCode();
      if (job_ != null) hash ^= Job.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ProjectId.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ProjectId);
      }
      if (job_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Job);
      }
      if (Region.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Region);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProjectId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ProjectId);
      }
      if (Region.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Region);
      }
      if (job_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Job);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SubmitJobRequest other) {
      if (other == null) {
        return;
      }
      if (other.ProjectId.Length != 0) {
        ProjectId = other.ProjectId;
      }
      if (other.Region.Length != 0) {
        Region = other.Region;
      }
      if (other.job_ != null) {
        if (job_ == null) {
          job_ = new global::Google.Cloud.Dataproc.V1.Job();
        }
        Job.MergeFrom(other.Job);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ProjectId = input.ReadString();
            break;
          }
          case 18: {
            if (job_ == null) {
              job_ = new global::Google.Cloud.Dataproc.V1.Job();
            }
            input.ReadMessage(job_);
            break;
          }
          case 26: {
            Region = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A request to get the resource representation for a job in a project.
  /// </summary>
  public sealed partial class GetJobRequest : pb::IMessage<GetJobRequest> {
    private static readonly pb::MessageParser<GetJobRequest> _parser = new pb::MessageParser<GetJobRequest>(() => new GetJobRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<GetJobRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[13]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GetJobRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GetJobRequest(GetJobRequest other) : this() {
      projectId_ = other.projectId_;
      region_ = other.region_;
      jobId_ = other.jobId_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GetJobRequest Clone() {
      return new GetJobRequest(this);
    }

    /// <summary>Field number for the "project_id" field.</summary>
    public const int ProjectIdFieldNumber = 1;
    private string projectId_ = "";
    /// <summary>
    ///  [Required] The ID of the Google Cloud Platform project that the job
    ///  belongs to.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ProjectId {
      get { return projectId_; }
      set {
        projectId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "region" field.</summary>
    public const int RegionFieldNumber = 3;
    private string region_ = "";
    /// <summary>
    ///  [Required] The Cloud Dataproc region in which to handle the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Region {
      get { return region_; }
      set {
        region_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "job_id" field.</summary>
    public const int JobIdFieldNumber = 2;
    private string jobId_ = "";
    /// <summary>
    ///  [Required] The job ID.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string JobId {
      get { return jobId_; }
      set {
        jobId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as GetJobRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(GetJobRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProjectId != other.ProjectId) return false;
      if (Region != other.Region) return false;
      if (JobId != other.JobId) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProjectId.Length != 0) hash ^= ProjectId.GetHashCode();
      if (Region.Length != 0) hash ^= Region.GetHashCode();
      if (JobId.Length != 0) hash ^= JobId.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ProjectId.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ProjectId);
      }
      if (JobId.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(JobId);
      }
      if (Region.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Region);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProjectId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ProjectId);
      }
      if (Region.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Region);
      }
      if (JobId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(JobId);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(GetJobRequest other) {
      if (other == null) {
        return;
      }
      if (other.ProjectId.Length != 0) {
        ProjectId = other.ProjectId;
      }
      if (other.Region.Length != 0) {
        Region = other.Region;
      }
      if (other.JobId.Length != 0) {
        JobId = other.JobId;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ProjectId = input.ReadString();
            break;
          }
          case 18: {
            JobId = input.ReadString();
            break;
          }
          case 26: {
            Region = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A request to list jobs in a project.
  /// </summary>
  public sealed partial class ListJobsRequest : pb::IMessage<ListJobsRequest> {
    private static readonly pb::MessageParser<ListJobsRequest> _parser = new pb::MessageParser<ListJobsRequest>(() => new ListJobsRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ListJobsRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[14]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ListJobsRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ListJobsRequest(ListJobsRequest other) : this() {
      projectId_ = other.projectId_;
      region_ = other.region_;
      pageSize_ = other.pageSize_;
      pageToken_ = other.pageToken_;
      clusterName_ = other.clusterName_;
      jobStateMatcher_ = other.jobStateMatcher_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ListJobsRequest Clone() {
      return new ListJobsRequest(this);
    }

    /// <summary>Field number for the "project_id" field.</summary>
    public const int ProjectIdFieldNumber = 1;
    private string projectId_ = "";
    /// <summary>
    ///  [Required] The ID of the Google Cloud Platform project that the job
    ///  belongs to.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ProjectId {
      get { return projectId_; }
      set {
        projectId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "region" field.</summary>
    public const int RegionFieldNumber = 6;
    private string region_ = "";
    /// <summary>
    ///  [Required] The Cloud Dataproc region in which to handle the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Region {
      get { return region_; }
      set {
        region_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "page_size" field.</summary>
    public const int PageSizeFieldNumber = 2;
    private int pageSize_;
    /// <summary>
    ///  [Optional] The number of results to return in each response.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PageSize {
      get { return pageSize_; }
      set {
        pageSize_ = value;
      }
    }

    /// <summary>Field number for the "page_token" field.</summary>
    public const int PageTokenFieldNumber = 3;
    private string pageToken_ = "";
    /// <summary>
    ///  [Optional] The page token, returned by a previous call, to request the
    ///  next page of results.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string PageToken {
      get { return pageToken_; }
      set {
        pageToken_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "cluster_name" field.</summary>
    public const int ClusterNameFieldNumber = 4;
    private string clusterName_ = "";
    /// <summary>
    ///  [Optional] If set, the returned jobs list includes only jobs that were
    ///  submitted to the named cluster.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ClusterName {
      get { return clusterName_; }
      set {
        clusterName_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "job_state_matcher" field.</summary>
    public const int JobStateMatcherFieldNumber = 5;
    private global::Google.Cloud.Dataproc.V1.ListJobsRequest.Types.JobStateMatcher jobStateMatcher_ = 0;
    /// <summary>
    ///  [Optional] Specifies enumerated categories of jobs to list
    ///  (default = match ALL jobs).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dataproc.V1.ListJobsRequest.Types.JobStateMatcher JobStateMatcher {
      get { return jobStateMatcher_; }
      set {
        jobStateMatcher_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ListJobsRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ListJobsRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProjectId != other.ProjectId) return false;
      if (Region != other.Region) return false;
      if (PageSize != other.PageSize) return false;
      if (PageToken != other.PageToken) return false;
      if (ClusterName != other.ClusterName) return false;
      if (JobStateMatcher != other.JobStateMatcher) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProjectId.Length != 0) hash ^= ProjectId.GetHashCode();
      if (Region.Length != 0) hash ^= Region.GetHashCode();
      if (PageSize != 0) hash ^= PageSize.GetHashCode();
      if (PageToken.Length != 0) hash ^= PageToken.GetHashCode();
      if (ClusterName.Length != 0) hash ^= ClusterName.GetHashCode();
      if (JobStateMatcher != 0) hash ^= JobStateMatcher.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ProjectId.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ProjectId);
      }
      if (PageSize != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(PageSize);
      }
      if (PageToken.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(PageToken);
      }
      if (ClusterName.Length != 0) {
        output.WriteRawTag(34);
        output.WriteString(ClusterName);
      }
      if (JobStateMatcher != 0) {
        output.WriteRawTag(40);
        output.WriteEnum((int) JobStateMatcher);
      }
      if (Region.Length != 0) {
        output.WriteRawTag(50);
        output.WriteString(Region);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProjectId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ProjectId);
      }
      if (Region.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Region);
      }
      if (PageSize != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PageSize);
      }
      if (PageToken.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(PageToken);
      }
      if (ClusterName.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ClusterName);
      }
      if (JobStateMatcher != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) JobStateMatcher);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ListJobsRequest other) {
      if (other == null) {
        return;
      }
      if (other.ProjectId.Length != 0) {
        ProjectId = other.ProjectId;
      }
      if (other.Region.Length != 0) {
        Region = other.Region;
      }
      if (other.PageSize != 0) {
        PageSize = other.PageSize;
      }
      if (other.PageToken.Length != 0) {
        PageToken = other.PageToken;
      }
      if (other.ClusterName.Length != 0) {
        ClusterName = other.ClusterName;
      }
      if (other.JobStateMatcher != 0) {
        JobStateMatcher = other.JobStateMatcher;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ProjectId = input.ReadString();
            break;
          }
          case 16: {
            PageSize = input.ReadInt32();
            break;
          }
          case 26: {
            PageToken = input.ReadString();
            break;
          }
          case 34: {
            ClusterName = input.ReadString();
            break;
          }
          case 40: {
            jobStateMatcher_ = (global::Google.Cloud.Dataproc.V1.ListJobsRequest.Types.JobStateMatcher) input.ReadEnum();
            break;
          }
          case 50: {
            Region = input.ReadString();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the ListJobsRequest message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      ///  A matcher that specifies categories of job states.
      /// </summary>
      public enum JobStateMatcher {
        /// <summary>
        ///  Match all jobs, regardless of state.
        /// </summary>
        [pbr::OriginalName("ALL")] All = 0,
        /// <summary>
        ///  Only match jobs in non-terminal states: PENDING, RUNNING, or
        ///  CANCEL_PENDING.
        /// </summary>
        [pbr::OriginalName("ACTIVE")] Active = 1,
        /// <summary>
        ///  Only match jobs in terminal states: CANCELLED, DONE, or ERROR.
        /// </summary>
        [pbr::OriginalName("NON_ACTIVE")] NonActive = 2,
      }

    }
    #endregion

  }

  /// <summary>
  ///  A list of jobs in a project.
  /// </summary>
  public sealed partial class ListJobsResponse : pb::IMessage<ListJobsResponse> {
    private static readonly pb::MessageParser<ListJobsResponse> _parser = new pb::MessageParser<ListJobsResponse>(() => new ListJobsResponse());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ListJobsResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[15]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ListJobsResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ListJobsResponse(ListJobsResponse other) : this() {
      jobs_ = other.jobs_.Clone();
      nextPageToken_ = other.nextPageToken_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ListJobsResponse Clone() {
      return new ListJobsResponse(this);
    }

    /// <summary>Field number for the "jobs" field.</summary>
    public const int JobsFieldNumber = 1;
    private static readonly pb::FieldCodec<global::Google.Cloud.Dataproc.V1.Job> _repeated_jobs_codec
        = pb::FieldCodec.ForMessage(10, global::Google.Cloud.Dataproc.V1.Job.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Dataproc.V1.Job> jobs_ = new pbc::RepeatedField<global::Google.Cloud.Dataproc.V1.Job>();
    /// <summary>
    ///  [Output-only] Jobs list.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Dataproc.V1.Job> Jobs {
      get { return jobs_; }
    }

    /// <summary>Field number for the "next_page_token" field.</summary>
    public const int NextPageTokenFieldNumber = 2;
    private string nextPageToken_ = "";
    /// <summary>
    ///  [Optional] This token is included in the response if there are more results
    ///  to fetch. To fetch additional results, provide this value as the
    ///  `page_token` in a subsequent &lt;code>ListJobsRequest&lt;/code>.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string NextPageToken {
      get { return nextPageToken_; }
      set {
        nextPageToken_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ListJobsResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ListJobsResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!jobs_.Equals(other.jobs_)) return false;
      if (NextPageToken != other.NextPageToken) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= jobs_.GetHashCode();
      if (NextPageToken.Length != 0) hash ^= NextPageToken.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      jobs_.WriteTo(output, _repeated_jobs_codec);
      if (NextPageToken.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(NextPageToken);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += jobs_.CalculateSize(_repeated_jobs_codec);
      if (NextPageToken.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(NextPageToken);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ListJobsResponse other) {
      if (other == null) {
        return;
      }
      jobs_.Add(other.jobs_);
      if (other.NextPageToken.Length != 0) {
        NextPageToken = other.NextPageToken;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            jobs_.AddEntriesFrom(input, _repeated_jobs_codec);
            break;
          }
          case 18: {
            NextPageToken = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A request to cancel a job.
  /// </summary>
  public sealed partial class CancelJobRequest : pb::IMessage<CancelJobRequest> {
    private static readonly pb::MessageParser<CancelJobRequest> _parser = new pb::MessageParser<CancelJobRequest>(() => new CancelJobRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<CancelJobRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[16]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public CancelJobRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public CancelJobRequest(CancelJobRequest other) : this() {
      projectId_ = other.projectId_;
      region_ = other.region_;
      jobId_ = other.jobId_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public CancelJobRequest Clone() {
      return new CancelJobRequest(this);
    }

    /// <summary>Field number for the "project_id" field.</summary>
    public const int ProjectIdFieldNumber = 1;
    private string projectId_ = "";
    /// <summary>
    ///  [Required] The ID of the Google Cloud Platform project that the job
    ///  belongs to.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ProjectId {
      get { return projectId_; }
      set {
        projectId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "region" field.</summary>
    public const int RegionFieldNumber = 3;
    private string region_ = "";
    /// <summary>
    ///  [Required] The Cloud Dataproc region in which to handle the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Region {
      get { return region_; }
      set {
        region_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "job_id" field.</summary>
    public const int JobIdFieldNumber = 2;
    private string jobId_ = "";
    /// <summary>
    ///  [Required] The job ID.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string JobId {
      get { return jobId_; }
      set {
        jobId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as CancelJobRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(CancelJobRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProjectId != other.ProjectId) return false;
      if (Region != other.Region) return false;
      if (JobId != other.JobId) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProjectId.Length != 0) hash ^= ProjectId.GetHashCode();
      if (Region.Length != 0) hash ^= Region.GetHashCode();
      if (JobId.Length != 0) hash ^= JobId.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ProjectId.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ProjectId);
      }
      if (JobId.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(JobId);
      }
      if (Region.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Region);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProjectId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ProjectId);
      }
      if (Region.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Region);
      }
      if (JobId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(JobId);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(CancelJobRequest other) {
      if (other == null) {
        return;
      }
      if (other.ProjectId.Length != 0) {
        ProjectId = other.ProjectId;
      }
      if (other.Region.Length != 0) {
        Region = other.Region;
      }
      if (other.JobId.Length != 0) {
        JobId = other.JobId;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ProjectId = input.ReadString();
            break;
          }
          case 18: {
            JobId = input.ReadString();
            break;
          }
          case 26: {
            Region = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  ///  A request to delete a job.
  /// </summary>
  public sealed partial class DeleteJobRequest : pb::IMessage<DeleteJobRequest> {
    private static readonly pb::MessageParser<DeleteJobRequest> _parser = new pb::MessageParser<DeleteJobRequest>(() => new DeleteJobRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<DeleteJobRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dataproc.V1.JobsReflection.Descriptor.MessageTypes[17]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public DeleteJobRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public DeleteJobRequest(DeleteJobRequest other) : this() {
      projectId_ = other.projectId_;
      region_ = other.region_;
      jobId_ = other.jobId_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public DeleteJobRequest Clone() {
      return new DeleteJobRequest(this);
    }

    /// <summary>Field number for the "project_id" field.</summary>
    public const int ProjectIdFieldNumber = 1;
    private string projectId_ = "";
    /// <summary>
    ///  [Required] The ID of the Google Cloud Platform project that the job
    ///  belongs to.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string ProjectId {
      get { return projectId_; }
      set {
        projectId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "region" field.</summary>
    public const int RegionFieldNumber = 3;
    private string region_ = "";
    /// <summary>
    ///  [Required] The Cloud Dataproc region in which to handle the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Region {
      get { return region_; }
      set {
        region_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "job_id" field.</summary>
    public const int JobIdFieldNumber = 2;
    private string jobId_ = "";
    /// <summary>
    ///  [Required] The job ID.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string JobId {
      get { return jobId_; }
      set {
        jobId_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as DeleteJobRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(DeleteJobRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProjectId != other.ProjectId) return false;
      if (Region != other.Region) return false;
      if (JobId != other.JobId) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProjectId.Length != 0) hash ^= ProjectId.GetHashCode();
      if (Region.Length != 0) hash ^= Region.GetHashCode();
      if (JobId.Length != 0) hash ^= JobId.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ProjectId.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(ProjectId);
      }
      if (JobId.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(JobId);
      }
      if (Region.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Region);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProjectId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(ProjectId);
      }
      if (Region.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Region);
      }
      if (JobId.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(JobId);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(DeleteJobRequest other) {
      if (other == null) {
        return;
      }
      if (other.ProjectId.Length != 0) {
        ProjectId = other.ProjectId;
      }
      if (other.Region.Length != 0) {
        Region = other.Region;
      }
      if (other.JobId.Length != 0) {
        JobId = other.JobId;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ProjectId = input.ReadString();
            break;
          }
          case 18: {
            JobId = input.ReadString();
            break;
          }
          case 26: {
            Region = input.ReadString();
            break;
          }
        }
      }
    }

  }

  #endregion

}

#endregion Designer generated code
